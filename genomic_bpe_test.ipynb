{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genomic BPE Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import collections\n",
    "\n",
    "from Bio import SeqIO\n",
    "from fastai.text import *\n",
    "\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_len=20480 #arbitrary number chosen. Original true \"max sentence length\" would be 44674217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes')\n",
    "path_to_files = path / 'genome_fastas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(path_to_files.iterdir()):\n",
    "    genome = SeqIO.parse(file, 'fasta')\n",
    "    chroms = [GB for GB in genome if 'chromosome' in GB.description] #  remove plasmid\n",
    "    genome = ''.join([i.seq.__str__() for i in chroms]).upper()\n",
    "    genome += '\\n'\n",
    "    with open('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/sentencepiece_tokenizer/all_files.txt', 'a') as f:\n",
    "        ind = 0\n",
    "        while ind < len(genome):\n",
    "            f.write(genome[ind:ind+max_sentence_len])\n",
    "            f.write('\\n')\n",
    "            ind += max_sentence_len\n",
    "    print('completed file {}/{}'.format(i,len(path_to_files.ls())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotemark = '\\\"'\n",
    "raw_text_path = '/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/sentencepiece_tokenizer/small_version_all_files.txt'\n",
    "lang = 'dna'\n",
    "pre_rules=None\n",
    "post_rules=None\n",
    "vocab_sz=None\n",
    "max_vocab_sz=10000\n",
    "model_type='bpe'\n",
    "char_coverage=None\n",
    "tmp_dir='tmp' \n",
    "enc='utf8'\n",
    "coverage = 0.9998\n",
    "spec_tokens = ['\\u2581'+s for s in defaults.text_spec_tok]\n",
    "spec_tokens.extend([str(i) for i in range(1, 21)])\n",
    "cache_dir = Path('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/sentencepiece_tokenizer')/tmp_dir\n",
    "\n",
    "#changed line in fastai.text see: https://forums.fast.ai/t/multifit-runtime-error-permission-denied/72874/3\n",
    "# in the end not creating model thru fastai. using sentencepiece package directly!\n",
    "print(\" \".join([\n",
    "        f\"--input={quotemark}{raw_text_path}{quotemark} --max_sentence_length={max_sentence_len}\",\n",
    "        f\"--character_coverage={coverage}\",\n",
    "        f\"--unk_id={len(defaults.text_spec_tok)} --pad_id=-1 --bos_id=-1 --eos_id=-1\",\n",
    "        f\"--user_defined_symbols={','.join(spec_tokens)}\",\n",
    "        f\"--model_prefix={cache_dir/'spm'} --vocab_size={10000} --model_type={model_type}\"]))\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\" \".join([\n",
    "        f\"--input={quotemark}{raw_text_path}{quotemark} --max_sentence_length={max_sentence_len}\",\n",
    "        f\"--character_coverage={coverage}\",\n",
    "        f\"--unk_id={len(defaults.text_spec_tok)} --pad_id=-1 --bos_id=-1 --eos_id=-1\",\n",
    "        f\"--user_defined_symbols={','.join(spec_tokens)}\",\n",
    "        f\"--model_prefix={cache_dir/'spm'} --vocab_size={10000} --model_type={model_type}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as spm\n",
    "s = spm.SentencePieceProcessor(model_file='/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/sentencepiece_tokenizer/tmp/spm.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = [[s.id_to_piece(id), id] for id in range(s.get_piece_size())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "test_text = \"\".join([random.choice(\"ATCG\") for _ in range(1000)])\n",
    "\n",
    "print(test_text)\n",
    "print(s.encode(test_text, out_type=str, enable_sampling=True, alpha=0.1)[0:10])\n",
    "print(s.encode(test_text, out_type=int, enable_sampling=True, alpha=0.1)[0:10])\n",
    "\n",
    "test_text_2 = \"1 2 3 4\"\n",
    "\n",
    "print(test_text_2)\n",
    "print(s.encode(test_text_2, out_type=str, enable_sampling=True, alpha=0.1)[0:10])\n",
    "print(s.encode(test_text_2, out_type=int, enable_sampling=True, alpha=0.1)[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Trying out model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Sentencepiece model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of devices: 8\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "import torch\n",
    "\n",
    "# sets device for model and PyTorch tensors\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\" # \"-1\" if want to run on a CPU, otherwise define the GPU number\n",
    "\n",
    "print('number of devices: {}'.format(torch.cuda.device_count()))\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import ( BaseTokenizer, Tokenizer, Vocab, \n",
    "                         PreProcessor, ItemList, PathOrStr, \n",
    "                         DataFrame, Optional, Collection, \n",
    "                         IntsOrStrs, DataBunch, is_listy, \n",
    "                         ItemLists, TextList, SortishSampler, \n",
    "                         DataLoader, SortSampler, partial, \n",
    "                         pad_collate, TextLMDataBunch, data_collate, \n",
    "                         LanguageModelPreLoader, SPProcessor, PreProcessor )\n",
    "from Bio import Seq\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import FeatureLocation, CompoundLocation\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.path.append(\"../..\")\n",
    "from utils import ( _get_genomic_processor, get_model_clas, TextClasDataBunch, \n",
    "                    get_scores, split_data, GenomicTokenizer, get_model_LM, \n",
    "                   GenomicVocab, GenomicTextClasDataBunch, GenomicTextLMDataBunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/ecoli/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'e_coli_lm_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, valid_df = split_data(df, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from fastai.text import ListRules, ifnone, defaults\n",
    "from fastai.text import ( BaseTokenizer, Tokenizer, Vocab, \n",
    "                         PreProcessor, ItemList, PathOrStr, \n",
    "                         DataFrame, Optional, Collection, \n",
    "                         IntsOrStrs, DataBunch, is_listy, \n",
    "                         ItemLists, TextList, SortishSampler, \n",
    "                         DataLoader, SortSampler, partial, \n",
    "                         pad_collate, TextLMDataBunch, data_collate, \n",
    "                         LanguageModelPreLoader, TextClasDataBunch, ifnone, \n",
    "                         is1d, AWD_LSTM, \n",
    "                         LinearDecoder, SequentialRNN, LanguageLearner, \n",
    "                         RNNLearner, awd_lstm_lm_split, MultiBatchEncoder, \n",
    "                         PoolingLinearClassifier, awd_lstm_clas_split, progress_bar )\n",
    "from fastai.text.data import _join_texts, apply_rules, ProcessPoolExecutor, partition_by_cores\n",
    "\n",
    "class GenomicSPProcessor(PreProcessor):\n",
    "    \"`PreProcessor` that tokenizes and numericalizes with `sentencepiece`\"\n",
    "    def __init__(self, ds:ItemList=None, pre_rules: ListRules=None, post_rules:ListRules=None, vocab_sz:int=None,\n",
    "                 max_vocab_sz:int=30000, model_type:str='unigram', max_sentence_len:int=20480, lang='en',\n",
    "                 char_coverage=None, tmp_dir='tmp', mark_fields:bool=False, include_bos:bool=True, \n",
    "                 include_eos:bool=False, sp_model=None, sp_vocab=None, n_cpus:int=None, enc='utf8'):\n",
    "        try: from sentencepiece import SentencePieceTrainer,SentencePieceProcessor\n",
    "        except ImportError:\n",
    "            raise Exception('sentencepiece module is missing: run `pip install sentencepiece`')\n",
    "        self.pre_rules,self.post_rules,self.enc = pre_rules,post_rules,enc\n",
    "        self.mark_fields,self.include_bos,self.include_eos = mark_fields,include_bos,include_eos\n",
    "        self.sp_model,self.sp_vocab,self.n_cpus = sp_model,sp_vocab,ifnone(n_cpus,defaults.cpus)\n",
    "        self.train_func = None\n",
    "        #partial(train_sentencepiece, pre_rules=pre_rules, post_rules=post_rules, vocab_sz=vocab_sz,\n",
    "        #        max_vocab_sz=max_vocab_sz, model_type=model_type, max_sentence_len=max_sentence_len, lang=lang,\n",
    "        #        char_coverage=char_coverage, tmp_dir=tmp_dir, enc=enc)\n",
    "\n",
    "    def process_one(self, item, join=True):\n",
    "        if join: text = _join_texts([item], self.mark_fields, self.include_bos, self.include_eos)[0]\n",
    "        text = apply_rules(text, pre_rules=self.pre_rules, post_rules=self.post_rules)\n",
    "        return self._encode_batch([text])[0]\n",
    "\n",
    "    def process(self, ds):\n",
    "        ds.items = _join_texts(ds.items, self.mark_fields, self.include_bos, self.include_eos)\n",
    "        ds.items = [apply_rules(t, pre_rules=self.pre_rules, post_rules=self.post_rules) \n",
    "                    for t in progress_bar(ds.items, leave=False)]\n",
    "        if self.sp_model is None or self.sp_vocab is None:\n",
    "            cache_dir = self.train_func(ds.items, ds.path)\n",
    "            self.sp_model,self.sp_vocab = cache_dir/'spm.model',cache_dir/'spm.vocab'\n",
    "        if not getattr(self, 'vocab', False): \n",
    "            with open(self.sp_vocab, 'r', encoding=self.enc) as f: self.vocab = Vocab([line.split('\\t')[0] for line in f.readlines()])\n",
    "        if self.n_cpus <= 1: ds.items = self._encode_batch(ds.items)\n",
    "        else:\n",
    "            with ProcessPoolExecutor(self.n_cpus) as e:\n",
    "                ds.items = np.array(sum(e.map(self._encode_batch, partition_by_cores(ds.items, self.n_cpus)), []))\n",
    "        ds.vocab = self.vocab\n",
    "\n",
    "    def _encode_batch(self, texts):\n",
    "        from sentencepiece import SentencePieceProcessor\n",
    "        tok = SentencePieceProcessor()\n",
    "        tok.Load(str(self.sp_model))\n",
    "        return [np.array(tok.encode_as_ids(texts))]\n",
    "        #return [np.array(tok.EncodeAsIds(t)) for t in texts]\n",
    "        \n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, path:PathOrStr, tmp_dir:PathOrStr='tmp', name:str='spm'):\n",
    "        cache_dir = Path(path)/tmp_dir\n",
    "        return cls(sp_model=cache_dir/f'{name}.model', sp_vocab=cache_dir/f'{name}.vocab')\n",
    "\n",
    "spm_dir = Path('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/sentencepiece_tokenizer/tmp/')\n",
    "gen_sp_processor =  GenomicSPProcessor(sp_model=spm_dir/'spm.model', \n",
    "                                       sp_vocab=spm_dir/'spm.vocab', \n",
    "                                       pre_rules=None, \n",
    "                                       post_rules=None, \n",
    "                                       vocab_sz=10000, \n",
    "                                       max_vocab_sz=10000, \n",
    "                                       model_type='bpe',\n",
    "                                       max_sentence_len=20480, \n",
    "                                       lang='dna', \n",
    "                                       char_coverage=0.9998, \n",
    "                                       tmp_dir='tmp', \n",
    "                                       mark_fields=False, \n",
    "                                       include_bos=True, \n",
    "                                       include_eos=True,  \n",
    "                                       enc='utf8')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_(text):\n",
    "    return text.replace('_', '').strip()\n",
    "\n",
    "def remove_from_list(texts):\n",
    "    #print('texts are: {}'.format(texts))\n",
    "    return [remove_single(text) for text in texts]\n",
    "\n",
    "def remove_single(text):\n",
    "    #print('applying ...')\n",
    "    #text = text.replace('xxup ', '') # remove uppercase indicator (useless)\n",
    "    text = text.upper() # make everything uppercase\n",
    "    text = text.replace('XXBOS', 'xxbos') # undo uppercasing BOS\n",
    "    text = text.replace('XXEOS', 'xxeos') # undo uppercasing EOS\n",
    "    #text = text.replace('XXUP', 'xxup')\n",
    "    #text = text.replace('XXREP', 'xxrep') # undo uppercasing REP\n",
    "    return text\n",
    "\n",
    "spm_dir = Path('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/sentencepiece_tokenizer/tmp/')\n",
    "gen_sp_processor = SPProcessor(sp_model=spm_dir/'spm.model', \n",
    "                               sp_vocab=spm_dir/'spm.vocab',\n",
    "                               pre_rules=[remove_], \n",
    "                               post_rules=[remove_from_list], \n",
    "                               vocab_sz=10000, \n",
    "                               model_type='bpe',\n",
    "                               max_sentence_len=20480, \n",
    "                               lang='dna', \n",
    "                               char_coverage=0.9998, \n",
    "                               tmp_dir='tmp', \n",
    "                               mark_fields=False, \n",
    "                               include_bos=True, \n",
    "                               include_eos=True,  \n",
    "                               enc='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from fastai.text.data import _join_texts, apply_rules, ProcessPoolExecutor, partition_by_cores\n",
    "\n",
    "def remove_(text):\n",
    "    return text.replace('_', '').strip()\n",
    "\n",
    "def remove_from_list(texts):\n",
    "    print('texts are: {}'.format(texts))\n",
    "    return [remove_single(text) for text in texts]\n",
    "\n",
    "def remove_single(text):\n",
    "    print('applying ...')\n",
    "    #text = text.replace('xxup ', '') # remove uppercase indicator (useless)\n",
    "    text = text.upper() # make everything uppercase\n",
    "    text = text.replace('XXBOS', 'xxbos') # undo uppercasing BOS\n",
    "    text = text.replace('XXEOS', 'xxeos') # undo uppercasing EOS\n",
    "    #text = text.replace('XXUP', 'xxup')\n",
    "    #text = text.replace('XXREP', 'xxrep') # undo uppercasing REP\n",
    "    return text\n",
    "\n",
    "#print(gen_sp_processor.process_one(train_df.iloc[0].Sequence[0:1000]))\n",
    "\n",
    "join = True\n",
    "item = train_df.iloc[0].Sequence[0:100]\n",
    "gen_sp_processor.post_rules = [remove_from_list] #[lambda x: x.upper()]\n",
    "gen_sp_processor.pre_rules = [remove_]\n",
    "\n",
    "print(item)\n",
    "if join: text = _join_texts([item], gen_sp_processor.mark_fields, gen_sp_processor.include_bos, gen_sp_processor.include_eos)[0]\n",
    "#text = item\n",
    "text = apply_rules(text, pre_rules=gen_sp_processor.pre_rules, post_rules=gen_sp_processor.post_rules)\n",
    "\n",
    "encoding = gen_sp_processor._encode_batch([text])[0]\n",
    "print('encoded: {}'.format(encoding))\n",
    "#print('decoded: {}'.format(gen_sp_processor.vocab.textify(encoding)))\n",
    "\n",
    "np.array(gen_sp_processor._encode_batch(['ACCT', 'CCAATCG']))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class GenomicTextLMDataBunchSP(TextLMDataBunch):\n",
    "    @classmethod\n",
    "    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n",
    "                processor:PreProcessor=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n",
    "                label_cols:IntsOrStrs=0, label_delim:str=None, bptt=70, collate_fn:Callable=data_collate, bs=64, **kwargs):\n",
    "        \"Create a `TextDataBunch` from DataFrames. `kwargs` are passed to the dataloader creation.\"\n",
    "        if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n",
    "        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n",
    "                        TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n",
    "        src = src.label_for_lm() \n",
    "        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n",
    "        d1 = src.databunch(**kwargs)\n",
    "        \n",
    "        datasets = cls._init_ds(d1.train_ds, d1.valid_ds, d1.test_ds)            \n",
    "        val_bs = bs\n",
    "        datasets = [LanguageModelPreLoader(ds, shuffle=(i==0), bs=(bs if i==0 else val_bs), bptt=bptt, backwards=False) \n",
    "                    for i,ds in enumerate(datasets)]            \n",
    "        dls = [DataLoader(d, b, shuffle=False) for d,b in zip(datasets, (bs,val_bs,val_bs,val_bs)) if d is not None]\n",
    "        \n",
    "        return cls(*dls, path=path, collate_fn=collate_fn, no_check=False)\n",
    "\n",
    "data = GenomicTextLMDataBunchSP.from_df(path, train_df, valid_df, bs=428, processor=gen_sp_processor, text_cols=0, label_cols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tokens: 10000\n",
      "first sequence: AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATTAAAAAAAGAGTGTCTGATAGCAGCTTCTGAACTGGTTACCTGCCGTGAGTAAATTAAAATTTTATTGACTTAGGTCACTAAATACTTTAACCAATATAGGCATAGCGCACAGACAGATAAAAATTACAGAGTACACAACATCCATGAAACGCATTAGCACCACCATTACCACCACCATCACCATTACCACAGGTAACGGTGCGGGCTGACGCGTACAGGAAACACAGAAAAAAGCCCGCACCTGACAGTGCGGGCTTTTTTTTTCGACCAAAGGTAACGAGGTAACAACCATGCGAGTGTTGAAGTTCGGCGGTACATCAGTGGCAAATGCAGAACGTTTTCTGCGTGTTGCCGATATTCTGGAAAGCAATGCCAGGCAGGGGCAGGTGGCCACCGTCCTCTCTGCCCCCGCCAAAATCACCAACCACCTGGTGGCGATGATTGAAAAAACCATTAGCGGCCAGGATGCTTTACCCAATATCAGCGATGCCGAACGTATTTTTGCCGAACTTTTGACGGGACTCGCCGCCGCCCAGCCGGGGTTCCCGCTGGCGCAATTGAAAACTTTCGTCGATCAGGAATTTGCCCAAATAAAACATGTCCTGCATGGCATTAGTTTGTTGGGGCAGTGCCCGGATAGCATCAACGCTGCGCTGATTTGCCGTGGCGAGAAAATGTCGATCGCCATTATGGCCGGCGTATTAGAAGCGCGCGGTCACAACGTTACTGTTATCGATCCGGTCGAAAAACTGCTGGCAGTGGGGCATTACCTCGAATCTACCGTCGATATTGCTGAGTCCACCCGCCGTATTGCGGCAAGCCGCATTCCGGCTGATCACATGGTGCTGATGGCA\n",
      "encoded: (Text [   2    9  188   50 ... 1597  369 9999    3], EmptyLabel 0)\n",
      "decoded: ▁xxbos <unk> AGCTT TTC AT TCT GAC TGCAAC GGGC AAT ATGTC TCT GTGT GGATT AAAA AA AGAGT GTCT GAT AGCAGC TTCT GAACT GGTT ACCTGCC GT GAGT AA ATTAA AAT TTTATT GACTT AGGTC ACT AAAT ACTTT AACC AAT AT AGGCAT AGCGCAC AGAC AGAT AAAA ATTAC AGA GTAC AC AACATCC ATGAA ACGC ATTAGC ACCACC ATT ACCACC ACC ATCACC ATT ACCAC AGGT AAC GGTGC GGGCT GACGC GTAC AGGA AACAC AGA AAAAAGCCC GC ACCT GAC AGTGC GGGC TTTT TT TTTC GACCAA AGGT AAC GAGGT AAC AACC ATGC GAGT GTTGAA GTTC GGCGGT ACATC AGT GGCAA ATGC AGA ACGT TTTC TGCGT GTTGCC GATAT TCTGGA AAGC AATGCC AGGC AGGGGC AGGT GGCCACC GTCCTC TCT GCCCCC GCCAA AATC ACC AACC ACCT GGTGGCGAT GATT GA AAAA ACC ATTAGC GGCC AGGA TGCTTT ACCCAAT ATCAGC GATGCC GAACGT ATTT TTGCC GAAC TTTT GAC GGGAC TC GCCGCC GCCCAGCC GGGGT TCCCGCT GGCGC AATT GAAAAC TTTC GTC GATC AGGA ATTT GCCC AAAT AAAAC ATGTCC TGC ATGGC ATT AGTTT GTT GGGGC AGTGCCC GGAT AGCATC AACGC TGCGCT GATTT GCCGT GGC GAGA AAATGTC GATCGCC ATT ATGGCC GGCGT ATT AGAAGC GCGC GGTCAC AAC GTT ACTGTT ATC GATCC GGTC GAAAAAC TGCT GGCAGT GGGGC ATT ACCTC GA ATCT ACC GTCGAT AT TGCT GAGTCC ACCC GCCGT ATTGC GGCAA GCCGC ATTCC GGCT GATC ACAT GGTGCT GATGGC A ▁xxeos\n"
     ]
    }
   ],
   "source": [
    "print('num tokens: {}'.format(len(data.vocab.itos)))\n",
    "print('first sequence: {}'.format(train_df.iloc[0].Sequence))\n",
    "print('encoded: {}'.format(data.train_ds[0]))\n",
    "encoding = gen_sp_processor.process_one(train_df.iloc[0].Sequence)\n",
    "print('decoded: {}'.format(gen_sp_processor.vocab.textify(encoding)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GCC',\n",
       " 'GGC',\n",
       " 'TCC',\n",
       " 'AT',\n",
       " 'GGA',\n",
       " 'AA',\n",
       " 'ACC',\n",
       " 'TT',\n",
       " 'GTC',\n",
       " 'GAC',\n",
       " 'GGT',\n",
       " 'AGC',\n",
       " 'TGC',\n",
       " 'ATC',\n",
       " 'GGCC',\n",
       " 'TTC',\n",
       " 'GAA',\n",
       " 'GAT',\n",
       " 'GTT',\n",
       " 'AAC']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vocab.itos[35:55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path/'coli_vocab_sp.npy', data.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=0, qrnn=False, output_p=0.25, \n",
    "                          hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15, tie_weights=True, out_bias=True)\n",
    "drop_mult = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_model_LM(data, drop_mult, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(10000, 400, padding_idx=0)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(10000, 400, padding_idx=0)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=10000, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='3' class='' max='4' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      75.00% [3/4 03:20<01:06]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.208111</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>8.685767</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>27.854570</td>\n",
       "      <td>#na#</td>\n",
       "      <td>01:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/32 00:00<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZxcZZX/8c/pPUsvSboT0lnIBsQQQwLNTsKiKOMgARHHHTUSGfGnjuOM4+iM+nKcwWXAQZmROCLyUnEZYYRB0BiBgIRAJyRsCZA9nQ7pLZ1e0nud3x91OzRNJ2mSunVvdX3fr1e9uuq599ZzqiCnn37uc881d0dERLJHTtQBiIhIeinxi4hkGSV+EZEso8QvIpJllPhFRLJMXtQBDEd5ebnPmDEj6jBERDLKunXrGty9YnB7RiT+GTNmUF1dHXUYIiIZxcx2DtWuqR4RkSyjxC8ikmWU+EVEsowSv4hIllHiFxHJMkr8IiJZRolfRCTLKPGLiMTQKwc6+fc/vMi2+raUv7cSv4hIDO1qOsj3/rSF2ubOlL+3Er+ISAy1dPQAUFyU+gILSvwiIjHU0plM/CWj8lP+3kr8IiIx1D/iL9GIX0QkO7R09gJQXKQRv4hIVmjt7GFUfi4FealP00r8IiIx1NLRS8mocCrnK/GLiMRQS2cPJSFM84ASv4hILLV09oSyogeU+EVEYqmlozeUNfygxC8iEkua6hERyTItHT06uSsiki3cndbOXo34RUSyRUdPH70J18ldEZFs0dKRvGpXI34RkSzxaoE2zfGLiGSFV0syZ9iI38xuN7M6M3tuQNvXzewZM9tgZn8ws8qw+hcRyVSHRvwZuI7/DuCyQW3fdvcF7r4Q+D/gn0PsX0QkIx2a48+0k7vuvhpoGtTWMuDlGMDD6l9EJFO1Hhrxh5P4w/k74gjM7BvAh4EDwMVH2G85sBxg+vTp6QlORCQGXq3Fn3lTPUNy9y+5+zTgZ8CnjrDfCnevcveqioqK9AUoIhKxlo4eCvNyKMrPDeX9o1zV83Pg6gj7FxGJpTArc0KaE7+ZnTTg5RXA5nT2LyKSCcKszAkhzvGb2V3ARUC5mdUAXwHeYWanAAlgJ3B9WP2LiGSqMCtzQoiJ393fN0Tzj8LqT0RkpGjp7KV0pEz1iIjI0bV29IR28RYo8YuIxM6IOrkrIiJH5u60dIRXix+U+EVEYqWrN0F3XyK0ypygxC8iEithV+YEJX4RkVgJuzInKPGLiMRKf50endwVEckS/VM9OrkrIpIl+kf8pTq5KyKSHTTiFxHJMq/eaF2JX0QkK7R09FKQm0NhXnjpWYlfRCRGWjp7KC7Kw8xC60OJX0QkRlo7e0Od5gElfhGRWGkJuTInKPGLiMRK2JU5QYlfRCRWkiN+JX4RkazR0tkbamVOUOIXEYkVjfhFRLJIV28fXb0JinVyV0QkO7SmoTInKPGLiMRGOur0gBK/iEhsvFqLX1M9IiJZQSN+EZEsk47KnKDELyISGy0dwVSPRvwiItmhNRjxZ+xyTjO73czqzOy5AW3fNrPNZvaMmd1jZmVh9S8ikmlaOnvIzTFGF+SG2k+YI/47gMsGta0E5rv7AuAl4Ish9i8iklFaOnopCbkWP4SY+N19NdA0qO0P7t4bvHwCmBpW/yIimSYdlTkh2jn+jwEPHG6jmS03s2ozq66vr09jWCIi0UhHnR6IKPGb2ZeAXuBnh9vH3Ve4e5W7V1VUVKQvOBGRiKSjMidA+D0MYmbXApcDb3F3T3f/IiJx1dLRw8TisaH3k9bEb2aXAV8ALnT3g+nsW0Qk7lo7ezN7qsfM7gLWAKeYWY2ZLQO+DxQDK81sg5n9IKz+RUQyTUtnT+hr+CHEEb+7v2+I5h+F1Z+ISCbr7OnjYHcf48YUhN6XrtwVEYmBxvZuACYo8YuIZIemtiDxjy0MvS8lfhGRGGho7wJgvEb8IiLZoTEY8ZePVeIXEckKjW3JEb+mekREskRTezeFeTmMCbkyJyjxi4jEQkNbNxPGFIRemROU+EVEYqGxvSst0zygxC8iEgtN7d1MSMOJXVDiFxGJhca27rQs5QQlfhGRyLk7DW1dlGuqR0QkOxzs7qOrN5GWcg2gxC8iErn+i7c01SMikiX6yzVoqkdEJEs0HirQphG/iEhWaGpPX7kGUOIXEYlcQ1v6avGDEr+ISOQa27oZU5BLUX74dXpAiV9EJHJNaSzXAEr8IiKRa2xP31W7oMQvIhK5hrbutNyApZ8Sv4hIxJrau5gwRlM9IiJZwd2TBdo04hcRyQ4tHb30JjxtSzlBiV9EJFKNaS7XAEr8IiKRamxPb7kGUOIXEYlUY1tyxD8ilnOa2e1mVmdmzw1ou8bMnjezhJlVhdW3iEim6C/XMFKmeu4ALhvU9hzwLmB1iP2KiGSMpmCqZ9zomI34zWyMmeUEz082syvMLP9Ix7j7aqBpUNsmd3/xmKMVERlhGtu6KCnKoyAvfTPvw+1pNVBkZlOAVcBHSY7oQ2Nmy82s2syq6+vrw+xKRCQyDe3daZ3mgeEnfnP3gySnab7n7lcB88ILC9x9hbtXuXtVRUVFmF2JiESmqa07rSt64A0kfjM7F/gAcH/QlhdOSCIi2aOxvSutK3pg+In/s8AXgXvc/XkzmwU8FF5YIiLZobGtO60lmWGYo3Z3fwR4BCA4ydvg7p8+0jFmdhdwEVBuZjXAV0ie7P0eUAHcb2Yb3P3txx6+iEjm6ks4+w92U57mEf+wEr+Z/Ry4HugD1gGlZnaTu3/7cMe4+/sOs+meNxyliMgI1Hywm4Sn7167/YY71TPP3VuAK4HfAdOBD4UWlYhIFugv1xDXOf78YN3+lcBv3b0H8PDCEhEZ+RqCcg1xXdVzG7ADGAOsNrMTgZawghIRyQb9V+2mex3/cE/u3gLcMqBpp5ldHE5IIiLZobEtxlM9ZlZqZjf1X0lrZv9OcvQvIiLHqLGtC7P01umB4U/13A60Au8JHi3Aj8MKSkQkGzS2dzN+dAG5OZbWfod79e1sd796wOuvmdmGMAISEckWjW3daZ/mgeGP+DvM7IL+F2Z2PtARTkgiItmhrrUz7Sd2Yfgj/uuBO82sNHi9H7g2nJBERLLD3gOdnDe7PO39DndVz0bgNDMrCV63mNlngWfCDE5EZKTq7Uuwr6WTyrKitPf9hir/u3tLcAUvwOdCiEdEJCvsa+0i4VBZNirtfR/PLV/SexpaRGQE2ducPE06uTTmI/5BVLJBROQY7QkS/5QIRvxHnOM3s1aGTvAGpD9aEZERYu+BTgAmxy3xu3txugIREckmtc0dFBflMbYw/TczTN9t3UVE5JDa5s5IpnlAiV9EJBJ7D3REcmIXlPhFRCJR29wRyVJOUOIXEUm7ju4+9h/sUeIXEckWtQeSSzmjuGoXlPhFRNJub3OwlLNUI34RkaxQG+HFW6DELyKSdrUHOjCDSSWa6hERyQq1zR2Ujy2kIC+aFKzELyKSZnsPdEa2ogeU+EVE0m5PcweVEV28BUr8IiJp5e7sbR6hI34zu93M6szsuQFt481spZm9HPwcF1b/IiJxdKCjh46evsjKNUC4I/47gMsGtf0DsMrdTwJWBa9FRLJGlHX4+4WW+N19NdA0qHkp8JPg+U+AK8PqX0Qkjg5dvDUSE/9hTHL3vQDBz4mH29HMlptZtZlV19fXpy1AEZEwHSrXMEKneo6Lu69w9yp3r6qoqIg6HBGRlKht7iQ/1ygfWxhZDOlO/PvMbDJA8LMuzf2LiESqtrmDE0qLyMmxyGJId+K/F7g2eH4t8Ns09y8iEqm9BzqojKg4W78wl3PeBawBTjGzGjNbBtwIXGpmLwOXBq9FRLJGbcRr+OEoN1s/Hu7+vsNsektYfYqIxFlfwnmlpTOyOvz9YntyV0RkpKlr7aQv4ZHV4e+nxC8ikia1wRr+KC/eAiV+EZG02Rus4Z+sqR4RkezQf+ctTfWIiGSJ7Q0HKRudT0lRaOtqhkWJX0QkTbbWtTGnYixm0V28BUr8IiJps6W+jTkTx0YdhhK/iEg6NLV309TezewKJX4Rkaywtb4NQCN+EZFssaVOiV9EJKtsrWujMC8n8jo9oMQvIpIWW+rbmFUxltwIyzH3U+IXEUmDLXXxWNEDSvwiIqHr6O5jT3MHsyvGRB0KoMQvIhK6bQ1tuMfjxC4o8YuIhC5OK3pAiV9EJHRb69vJMZgxQVM9IiJZYWtdG9PGj6YoPzfqUAAlfhGR0G0JirPFhRK/iEiI+hLO9ob22MzvgxK/iEiodjcdpLsvEYvibP2U+EVEQtS/omd2jEb80d4GJmQ3PrCZ/1lXE1n/R7rXwhu9aPvI7/XajYP3tddsG/qN+psP/QyOMnv1+P5jD73DoG12aH9L/gzacnKSbTnBDjkGOcFPG/A6N8cwM/JyjJzgZ26ukZ9j5OXmkJ+bQ0GuUZSfS1F+LqMKchlTkEtFcRGTSgqZVFLExOJC8nI1npH4OFSVM0Yj/hGd+N80uZi3nTopkr7dj7g1Ze81eJsPeu+B2we/Tf+2Q8e89gfuPuD54bfhyfdwT+7nOAnvP6b/eXL/Q88dEu7JRwJ6PUHCnT6HvkSCvgQkEk5PIkFfwunpTdCTcLp7E3T19tHZkxjy+yjIy+HUyhIWTitj4bQyTp8+jqnjRkV+xyPJXlvq2igfW0jp6PyoQzlkRCf+pQunsHThlKjDkBAkEk5Xb4LWrh7qWrqoa+1kX0sXW+va2FjTzF1P7uLHf94BwOTSIqpmjOesGeOomjGekycVx6JQlmSH5F234rF+v9+ITvwycuXkGKMKktM9E4uLgNLXbO/pS/DiK62s37WfJ7c38eT2Ru7bWAtAcVEeZ5w4jjNnjOeME8dx2tQyRhXEY321jCzuzta6Nq5YWBl1KK+hxC8jUn5uDvOnlDJ/SikfPncG7k7N/g6qdzbx1I79VO9o4tu/fxGAvBzj1CmlnHniOM6bM4EzZ4ynuCg+f5ZL5qpv66KlszdWK3ogosRvZp8BriN5bvCH7v7dKOKQ7GFmTBs/mmnjR3PVoqkANB/sZv2u/VTv2E/1zv3c+cRO/vux7eTmGG+eUsqSk8p526kncGplic4RyDF58ZVWAE6aWBxxJK+V9sRvZvNJJv2zgG7gQTO7391fTncskt3KRhdwydxJXDI3uQCgs6eP9bv2s2ZrI49vbeT7D23hlj9tobK0iLfOm8SVi6awaFqZfgnIsD21vYkcg9OmlR595zSKYsT/JuAJdz8IYGaPAFcB34ogFpFDivJzOW92OefNLudvgab2blZt2sfKF/bxq+rd3LlmJ3NPKOYDZ09n6aIplGg6SI7iie1NnFpZGrupwygWPD8HLDGzCWY2GngHMG3wTma23Myqzay6vr4+7UGKjB9TwDVV01jx4Sqqv3wp37hqPrk5xj/99nnO+ddV/NsDm2hq7446TImpzp4+Nuxu5uyZ46MO5XXSPuJ3901m9k1gJdAGbAR6h9hvBbACoKqq6o0tfBdJsbGFeXzg7BN5/1nTeXbPAX702HZWrN7GT9fs5CPnz+C6xbMoG10QdZgSIxt2N9Pdm+DsWROiDuV1IrnE0d1/5O6nu/sSoAnQ/L5kBDNjwdQy/uO9i1j5N0u4eO5E/vPhrSz+5kP8cPU2unuHvrBMss/abU2YwVkz4jfijyTxm9nE4Od04F3AXVHEIXI85kws5vvvP50HPrOYM2aM4xu/28Tbv7uaP76wDz/ypduSBdZub2TuCSWxumK3X1RFTX5jZi8A9wE3uPv+iOIQOW5zTyjhjo+exY8/eiY5Bh+/s5prf/wU2xvaow5NItLdm2D9rv2xnN+HiNbxu/viKPoVCdPFp0zkgjnl3LlmJ99d+RJvv3k1n7hwFp+8aI6uDM4yz9Q009mT4JxZ8Uz8KmMokkL5uTksu2Amqz5/IX+5YDLf+9MWLr35EVa+sC/q0CSN1m5vAuCsmfE7sQtK/CKhmFhcxM1/tZBfLD+H0QW5XHdnNcvueIrdTQejDk3SYO32Jk6eNJbxY+K50kuJXyRE58yawP2fXsw/vmMua7Y18tabHuGWVS/T2dMXdWgSkt6+BOt2NHFWTOf3QYlfJHT5uTksXzKbVX97IW+dN4mbVr7E225ezapNmv4ZiZ6rbaG9u4+zYzrNA0r8ImkzuXQUt77/dH667Gzyc41lP6nmY3c8xY40rf5J3sCmj47u5KOnT9cchGHttkYAzo7piV1QWWaRtLvgpHIe+MwSfvL4Dv5j1cu87ebVfOyCmXzqkjmMLTy2f5LuzvO1LWzY3UzN/g5q9h+kZn8HzQe7ae3spbWzl+5BiT4/11g4rYzzZpdz/pxyFk4royBPY8HjtXZ7E7PKxwT3iYgny4QLTaqqqry6ujrqMERSrq6lkxsf3Mzd6/cwsbiQf/iLuVy5cAo5w7xD2Ev7WrlvYy33baxlR2PyxHF+rjGlbBRTxo1iwphCiovyKC7KZ2xhLrk5ycRuBvvbu1mzrZFn9xzAHcrHFnLd4pl88JwTGXOMv4CyXU9fgtO/vpLLF0zm3961IOpwMLN17l71unYlfpHord+1n6/d+zwbaw6wcFoZ//zOeZw+fdwRj/nO71/k+w9tIcfg3NkTeOeCSpacXMGkkqI3dGvJAwd7WLOtgZ8+sYvHtjRQNjqfZefP5MPnzaB0VPyuOo2zP76wj4/fWc0PP1zFpfOiud/3QEr8IjGXSDi/WV/Dt37/IvWtXVy5sJK/v2wulWWjXrfvXU/u4ot3P8u7z5jKFy6bS0VxYUpiWL9rP7f+aQurNtclC9OdM51lF8yM9bRFnNzws/Ws2dbI2n98C/m50U+bKfGLZIi2rl7+6+Et/PDR7eQYLF8ym08smXVo+uWRl+r52B1Psfikcv77w1XkhZBgnq89wH89vJXfPbuXvNwcrjljKtdfOJtp40envK+R4kBHD2d+44+878xpfG3p/KjDAZT4RTLO7qaD3PjAZu5/di8Tiwv5/NtO4dQpJfzVbU8wbfxofn39ucd8Mni4djS0c9vqbfxmXQ0Jd64+fSo3XDyH6RP0C2Cw/r/CfnvD+Zw2rSzqcAAlfpGMtW5nE/9y/yae3tVMjkFFcSH/e8P5TC59/RRQWPYe6OC2R7bx8yd30Zdwrlo0hU9dPIcZ5WPSFkPcvecHa2ho72LV5y6Mze05lfhFMpi783/P7OXX62r4wmWncGplNPdw3dfSyQ8e2crP1+6iN+EsXVjJpy6ew6yKsZHEExe7mw6y+FsP8XdvP4UbLp4TdTiHKPGLSMrUtXQm70C2difdvQkuX1DJxxfPZMHUeExxpNstq17mppUv8dgXLmbquPhMgx0u8Wuxroi8YRNLivjy5fP4xIWz+e9Ht/Gztbu4d2MtZ84Yx7ILZnLx3IkU5mVHKWp35+71NZwza3yskv6RKPGLyDGrKC7ki+94E5+6ZA6/fGo3dzy+g+t/uv7QtsqyUVSWFjGppIiK4kIqiguZOm4UZ84YH4vljqnw9O5mdjQe5JMXxWeK52iU+EXkuBUX5fPxxbP4yHkzeOjFel6obaG2uYPaAx28tK+Vx7Y00NrZe2j/8rEFXHHaFN51+hROrSyJzcnQY/GbdTUU5uXwF28+IepQhk2JX0RSJi83h0vnTRryqtWO7j4a2rp4YW8L//v0Hn76xE5u//N2TplUzLvPmMrSRZUZd6HYy/ta+VX1bq5aNIXiosy5ylknd0UkEs0Hu7nvmb3cvb6Gp3c1k5tjXHhyBdecMZW3vGlS7AvGJRLOe25bw5b6Nv74uQspH5uaq6dTSSd3RSRWykYX8KFzTuRD55zI1vo2frOuhrvX7+GvN69nwpgCrj5jKu+pmsacifFcKvqLp3ZTvXM/3373glgm/SPRiF9EYqMv4ax+uZ5fPrmbP27aR2/CWTitjKsWTeHyBZOZEJMEW9fSyVtueoT5laX8/LqzY3uOQuv4RSSj1Ld2cc/TNdzzdC2b9raQl2MsObmCpQsruXTeJEYXRDdhccPP1rNy0z5+/9klzIzx1cua6hGRjFJRXMjyJbNZvmQ2m19p4Z6n93Dvhlr+tLmOUfm5XDpvEksXVrL4pIq0ng/47YY93P/sXj7/tpNjnfSPRCN+EckYiYTz1I4mfruxlt89u5fmgz2UjsrnslNP4PLTJnPurAmhVCuF5IVaK1Zv48YHN7NwWhm/XH5u7E9Aa6pHREaU7t4Ej22p576Ne/nD86/Q3t3HuNH5XDI3uZx0ycnlKZsO6u5N8KV7nuXX62r4yzdP5jvXnMaogvhfmaypHhEZUQrycrhk7iQumTuJzp4+Htpcx++ff4WVL7zCb9YnL6o6a+Z4LpiTvKfwvMklw76lZT93Z/2u/XzzwRd5cnsTn75kDp9968lv+H3iRiN+ERlRevoSPLW9iZWb9vHnLQ28tK8NgNJR+SyYWsr8KaXMryzllBOKqSgupKQo79CqnL6E09jexe6mDla+sI/7Ntayp7mDUfm53Hj1m1m6cEqUH+0Ni9VUj5n9DfBxwIFngY+6e+fh9lfiF5FjVdfSyeNbG3kiuLH8i6+00pt4Ne8V5OVQPqaAPnca2rrpC7bl5hiLTyrnitOSq4gy6crcfrGZ6jGzKcCngXnu3mFmvwLeC9yR7lhEZOSbWFLElYumcOWi5Gi9q7ePF19pZWt9Gw2t3TS0dVHf1kWuGZNKiphUUsjEkiLOnDGe8WMKIo4+HFHN8ecBo8ysBxgN1EYUh4hkmcK8XBZMLcvaewcApH0tkrvvAb4D7AL2Agfc/Q+D9zOz5WZWbWbV9fX16Q5TRGTESnviN7NxwFJgJlAJjDGzDw7ez91XuHuVu1dVVFSkO0wRkREriqsP3gpsd/d6d+8B7gbOiyAOEZGsFEXi3wWcY2ajLbmG6i3ApgjiEBHJSlHM8a8F/gdYT3IpZw6wIt1xiIhkq0hW9bj7V4CvRNG3iEi2i3eFIRERSTklfhGRLJMRtXrM7ADw8hCbSoEDw3w91POBbeVAwzGEN7jP4W5X7EmZGvuxxn2k2I62XbEr9je6/SR3L31dq7vH/gGsGE77kV4P9XxQW3UqY1PsIzv2Y41bsSv2KGPvf2TKVM99w2w/0uuhnh/ufd+Io72HYn/9c8V+bNsV+/FR7IGMmOpJBzOr9iGq2GUCxZ5+mRo3KPaoxCn2TBnxp0MmX0ug2NMvU+MGxR6V2MSuEb+ISJbRiF9EJMso8YuIZJkRl/jN7HYzqzOz547h2DPM7Fkz22Jmt1j/jTiT295jZi+Y2fNm9vPURn2oj5THbmYfMbN6M9sQPD6e+sjD+96D7e82MzezUE6MhfS9Xx+0bzCzx8xsXuojDy32zwX/rz9jZqvM7MTURx5a7EvMbL2Z9ZrZu+MU82He71ozezl4XDugfaaZrQ3af2lmqb0V2LGuK43rA1gCnA48dwzHPgmcCxjwAPAXQftJwNPAuOD1xAyK/SPA9zPxew+2FQOrgSeAqkyJHSgZsM8VwIMZFPvFwOjg+V8Dv8yg2GcAC4A7gXfHJWbgYWDGoLbxwLbg57jgeX+O+RXw3uD5D4C/TuXnGHEjfndfDTQNbDOz2Wb2oJmtM7NHzWzu4OPMbDLJf6xrPPlt3wlcGWy+DrjV3fcHfdRlUOxpEWLsXwe+BXRmUuzu3jJg1zFAKKsoQor9IXc/GOz6BDA1g2Lf4e7PAIk4xXwYbwdWuntTkFtWApcFf71cQrKKMcBPSPG/5xGX+A9jBfD/3P0M4PPAfw6xzxSgZsDrmqAN4GTgZDP7s5k9YWaXhRrtax1v7ABXB3+2/4+ZTQsv1Nc5rtjNbBEwzd3/L+xAh3Dc37uZ3WBmW0n+4vp0iLEOlor/Z/otIzmiTpdUxp4uw4l5KFOA3QNe93+OCUCzu/cOak+ZqG62njZmNpbkHb5+PWDquHCoXYdo6x+l5ZGc7rmI5OjnUTOb7+7NqY12UECpif0+4C537zKz60mOHi5JdayvC+g4YzezHOBmklNVaZWi7x13vxW41czeD3wZuHaI/VMqVbEH7/VBoAq4MJUxHk4qY0+XI8VsZh8FPhO0zQF+Z2bdJO9AeBWH/xyhf74Rn/hJ/lXT7O4LBzaaWS6wLnh5L/BfvPZP2qlAbfC8BnjCk7eK3G5mL5L8RfBUmIGTgtjdvXFA+w+Bb4YW7Wsdb+zFwHzg4eAf1AnAvWZ2hbtXxzz2wX4R7JsOKYndzN4KfAm40N27Qo34Van+3tNhyJgB3P3HwI8BzOxh4CPuvmPALjUkB5P9ppI8F9AAlJlZXjDqT/3nS/XJjzg8SJ7geW7A68eBa4LnBpx2mOOeAs7h1RNG7wjaLwN+EjwvJ/nn2YQMiX3ygH2uIvkLLCO+90H7PExIJ3dD+t5PGrDPOzmOAl0RxL4I2DrwM2RK7AO230EIJ3ePNWYOf3J3O8kTu+OC5+ODbb/mtSd3P5nSzxD2f9h0P4C7gL1AD8nfqMuAmcCDwEbgBeCfD3NsFfBc8D/993n1ymYDbgqOfbb/P0iGxP5vwPPB8Q8BczMl9kH7PEx4q3rC+N7/I/jeNwTf+6kZFPsfgX1B7BuAezMo9jOD92oHGoHn4xAzQyT+oP1jwJbg8dEB7bNIrlzaQvKXQGEqP4dKNoiIZJlsWdUjIiIBJX4RkSyjxC8ikmWU+EVEsowSv4hIllHil4xlZm1p7u/xFL3PRWZ2wMyeNrPNZvadYRxzpYVU4VOyjxK/SMDMjnglu7ufl8LuHnX3RSQvlrrczM4/yv5XAkr8khLZULJBsoiZzQZuBSqAg8B17r7ZzN5Jsl5OAckLez7g7vvM7KtAJcmrMRvM7CVgOskLaKYD33X3W4L3bnP3sWZ2EfBVkpfWzydZTuCD7u5m9g6SF/s1AOuBWe5++eHidfcOM9vAq4XprgOWB3FuAT4ELCRZ2vlCM/sycHVw+Os+53F8dZJFNOKXkeZwlRIfA84JRtm/AP5+wDFnAEvd/f3B67kkS+aeBXzFzPKH6GcR8FmSo/BZwPlmVgTcRrI2/AUkk/IRmdk4knWfVgdNd7v7me5+GrAJWObuj5OsUfN37r7Q3bce4XOKHJVG/DJiHBsUOCEAAAGDSURBVKW641Tgl0Et9wKSdVH63evuHQNe3+/JwmRdZlYHTOK1ZYABnnT3mqDfDST/YmgDtrl7/3vfRXL0PpTFZvYMcApwo7u/ErTPN7N/AcqAscDv3+DnFDkqJX4ZSQ5bKRH4HnCTu987YKqmX/ugfQdWo+xj6H8nQ+0zVDndw3nU3S83s5OBx8zsHnffQLK42JXuvtHMPsJrqzf2O9LnFDkqTfXIiOHJu15tN7NrACzptGBzKbAneB5WXfzNwCwzmxG8/qujHeDuL5EspPeFoKkY2BtML31gwK6twbajfU6Ro1Lil0w22sxqBjw+RzJZLjOzjSSrYy4N9v0qyamRR0meeE25YLrok8CDZvYYyQqXB4Zx6A+AJWY2E/gnYC3J2/ANPFn7C+DvgiWgszn85xQ5KlXnFEkhMxvr7m3BfVNvBV5295ujjktkII34RVLruuBk7/Mkp5duizgekdfRiF9EJMtoxC8ikmWU+EVEsowSv4hIllHiFxHJMkr8IiJZ5v8DYKPnuO+rOHkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/10 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      15.62% [5/32 00:10<00:57 9.1282]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 5e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('coli_only_LM_sp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('coli_only_LM_enc_sp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Classification downstream task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/ecoli/')\n",
    "classification_df = pd.read_csv(path/'e_coli_promoters_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = classification_df[classification_df.set == 'train']\n",
    "valid_df = classification_df[classification_df.set == 'valid']\n",
    "test_df = classification_df[classification_df.set == 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = np.load(path/'coli_vocab_sp.npy')\n",
    "model_vocab = GenomicVocab(voc)\n",
    "\n",
    "spm_dir = Path('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/sentencepiece_tokenizer/tmp/')\n",
    "gen_sp_processor = SPProcessor(sp_model=spm_dir/'spm.model', \n",
    "                               sp_vocab=spm_dir/'spm.vocab', \n",
    "                               pre_rules=None, \n",
    "                               post_rules=None, \n",
    "                               vocab_sz=10000, \n",
    "                               max_vocab_sz=10000, \n",
    "                               model_type='bpe',\n",
    "                               max_sentence_len=20480, \n",
    "                               lang='dna', \n",
    "                               char_coverage=0.9998, \n",
    "                               tmp_dir='tmp', \n",
    "                               mark_fields=False, \n",
    "                               include_bos=True, \n",
    "                               include_eos=True,  \n",
    "                               enc='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomicTextClasDataBunchSP(TextClasDataBunch):\n",
    "    @classmethod\n",
    "    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n",
    "                processor:PreProcessor=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n",
    "                label_cols:IntsOrStrs=0, pad_idx=1, pad_first=True, label_delim:str=None,\n",
    "                bs=64, **kwargs) -> DataBunch:\n",
    "        \"Create a `TextDataBunch` from DataFrames. `kwargs` are passed to the dataloader creation.\"\n",
    "        if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n",
    "        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n",
    "                        TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n",
    "        src = src.label_from_df(cols=label_cols, classes=classes, label_delim=label_delim)\n",
    "        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n",
    "        d1 = src.databunch(**kwargs)\n",
    "        \n",
    "        datasets = cls._init_ds(d1.train_ds, d1.valid_ds, d1.test_ds)\n",
    "        collate_fn = partial(pad_collate, pad_idx=pad_idx, pad_first=pad_first, backwards=False)\n",
    "        train_sampler = SortishSampler(datasets[0].x, key=lambda t: len(datasets[0][t][0].data), bs=bs//2)\n",
    "        train_dl = DataLoader(datasets[0], batch_size=bs, sampler=train_sampler, drop_last=True, **kwargs)\n",
    "        dataloaders = [train_dl]\n",
    "        for ds in datasets[1:]:\n",
    "            lengths = [len(t) for t in ds.x.items]\n",
    "            sampler = SortSampler(ds.x, key=lengths.__getitem__)\n",
    "            dataloaders.append(DataLoader(ds, batch_size=bs, sampler=sampler, **kwargs))\n",
    "            \n",
    "        return cls(*dataloaders, path=path, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tok = Tokenizer(GenomicTokenizer, n_cpus=1, pre_rules=[], post_rules=[], special_cases=['xxpad'])\n",
    "data_clas = GenomicTextClasDataBunchSP.from_df(path, train_df, valid_df, processor=gen_sp_processor,\n",
    "                                             text_cols='Sequence', label_cols='Promoter', bs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=0, qrnn=False, output_p=0.4, \n",
    "                       hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5)\n",
    "drop_mult = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_model_clas(data_clas, drop_mult, clas_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load_encoder('coli_only_LM_enc_sp')\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(3, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(3, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(3, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit_one_cycle(5, slice(1e-4/(2.6**4),1e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('coli_coli_pretrain_sp', return_path=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = GenomicTextClasDataBunchSP.from_df(path, train_df, test_df, processor=gen_sp_processor,\n",
    "                                            text_cols='Sequence', label_cols='Promoter', bs=300)\n",
    "learn.data = data_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_scores(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (genomic_ulmfit)",
   "language": "python",
   "name": "genomic_ulmfit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
