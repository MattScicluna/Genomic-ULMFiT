{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genomic BPE Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import collections\n",
    "\n",
    "from Bio import SeqIO\n",
    "from fastai.text import *\n",
    "\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sentence_len=20480 #44674217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes')\n",
    "path_to_files = path / 'genome_fastas'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, file in enumerate(path_to_files.iterdir()):\n",
    "    genome = SeqIO.parse(file, 'fasta')\n",
    "    chroms = [GB for GB in genome if 'chromosome' in GB.description] #  remove plasmid\n",
    "    genome = ''.join([i.seq.__str__() for i in chroms]).upper()\n",
    "    genome += '\\n'\n",
    "    with open('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/sentencepiece_tokenizer/all_files.txt', 'a') as f:\n",
    "        ind = 0\n",
    "        while ind < len(genome):\n",
    "            f.write(genome[ind:ind+max_sentence_len])\n",
    "            f.write('\\n')\n",
    "            ind += max_sentence_len\n",
    "    print('completed file {}/{}'.format(i,len(path_to_files.ls())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  changed line in fastai.text see: https://forums.fast.ai/t/multifit-runtime-error-permission-denied/72874/3\n",
    "#SPProcessor??\n",
    "#test_proc = SPProcessor(max_vocab_sz=10000)\n",
    "#ds = TextList.from_folder(path)\n",
    "#test_proc.train_func\n",
    "#test_proc.process??\n",
    "#test_proc.process(TextList.from_folder(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quotemark = '\\\"'\n",
    "raw_text_path = '/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/sentencepiece_tokenizer/small_version_all_files.txt'\n",
    "lang = 'dna'\n",
    "pre_rules=None\n",
    "post_rules=None\n",
    "vocab_sz=None\n",
    "max_vocab_sz=10000\n",
    "model_type='bpe'\n",
    "char_coverage=None\n",
    "tmp_dir='tmp' \n",
    "enc='utf8'\n",
    "coverage = 0.9998\n",
    "spec_tokens = ['xxunk', 'xxpad', 'xxbos', 'xxeos'] #['\\u2581'+s for s in defaults.text_spec_tok]\n",
    "cache_dir = Path('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/sentencepiece_tokenizer')/tmp_dir\n",
    "\n",
    "print(\" \".join([\n",
    "        f\"--input={quotemark}{raw_text_path}{quotemark} --max_sentence_length={max_sentence_len}\",\n",
    "        f\"--character_coverage={coverage}\",\n",
    "        f\"--unk_id={len(defaults.text_spec_tok)} --pad_id=-1 --bos_id=-1 --eos_id=-1\",\n",
    "        f\"--user_defined_symbols={','.join(spec_tokens)}\",\n",
    "        f\"--model_prefix={cache_dir/'spm'} --vocab_size={30000} --model_type={model_type}\"]))\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\" \".join([\n",
    "        f\"--input={quotemark}{raw_text_path}{quotemark} --max_sentence_length={max_sentence_len}\",\n",
    "        f\"--character_coverage={coverage}\",\n",
    "        f\"--unk_id={len(defaults.text_spec_tok)} --pad_id=-1 --bos_id=-1 --eos_id=-1\",\n",
    "        f\"--user_defined_symbols={','.join(spec_tokens)}\",\n",
    "        f\"--model_prefix={cache_dir/'spm'} --vocab_size={30000} --model_type={model_type}\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = spm.SentencePieceProcessor(model_file='/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/sentencepiece_tokenizer/tmp/spm.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = [[s.id_to_piece(id), id] for id in range(s.get_piece_size())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AATCGCGTTCGGC', 29993]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs[-7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁',\n",
       " 'C',\n",
       " 'C',\n",
       " 'AGGA',\n",
       " 'GAAAT',\n",
       " 'TACT',\n",
       " 'GTTC',\n",
       " 'GCGCAC',\n",
       " 'GTTC',\n",
       " 'ATGT',\n",
       " 'AACCCT',\n",
       " 'GGCCATC',\n",
       " 'TCTTCCC',\n",
       " 'AACTT',\n",
       " 'GATAAAC',\n",
       " 'AAGGAC',\n",
       " 'GAATC',\n",
       " 'TTTCC',\n",
       " 'AA',\n",
       " 'GGCCC',\n",
       " 'TCCTAC',\n",
       " 'AAGTT',\n",
       " 'GTCGT',\n",
       " 'GATCCC',\n",
       " 'GAAT',\n",
       " 'AGAGCC',\n",
       " 'GAGCGA',\n",
       " 'C',\n",
       " 'TT',\n",
       " 'GGC',\n",
       " 'AGGAAT',\n",
       " 'ACTA',\n",
       " 'G',\n",
       " 'C',\n",
       " 'TAC',\n",
       " 'AAATTTT',\n",
       " 'AGTGCTCAT',\n",
       " 'AAAC',\n",
       " 'GC',\n",
       " 'AGTC',\n",
       " 'GGCTAT',\n",
       " 'TCCCAGT',\n",
       " 'AATAGA',\n",
       " 'TAT',\n",
       " 'ATCC',\n",
       " 'GGATGC',\n",
       " 'AGTT',\n",
       " 'GATTGC',\n",
       " 'GGAGAC',\n",
       " 'TGCGTCTT',\n",
       " 'GAAC',\n",
       " 'ACAT',\n",
       " 'GTGCGA',\n",
       " 'GGCATTC',\n",
       " 'GGT',\n",
       " 'TGCTT',\n",
       " 'GATGT',\n",
       " 'TACTGC',\n",
       " 'GACGC',\n",
       " 'TTTAA',\n",
       " 'ACAA',\n",
       " 'GGAC',\n",
       " 'ACT',\n",
       " 'ACTCAGA',\n",
       " 'GTT',\n",
       " 'GGGCGC',\n",
       " 'TTAAAT',\n",
       " 'TTAAT',\n",
       " 'TGCAC',\n",
       " 'AGGGC',\n",
       " 'GCCCTC',\n",
       " 'ATCT',\n",
       " 'GA',\n",
       " 'T',\n",
       " 'TCCAC',\n",
       " 'TCCTT',\n",
       " 'GTTGA',\n",
       " 'TCCGT',\n",
       " 'ATAA',\n",
       " 'GTTATC',\n",
       " 'AGGTT',\n",
       " 'AAGT',\n",
       " 'GCCGT',\n",
       " 'ACCT',\n",
       " 'GACTT',\n",
       " 'GAGACCC',\n",
       " 'ATTAC',\n",
       " 'TCC',\n",
       " 'AATT',\n",
       " 'AT',\n",
       " 'GGATGAT',\n",
       " 'GAGGTC',\n",
       " 'AGGCCT',\n",
       " 'GATTC',\n",
       " 'ACT',\n",
       " 'AGGCGC',\n",
       " 'ATGC',\n",
       " 'AGGA',\n",
       " 'AT',\n",
       " 'GC',\n",
       " 'G',\n",
       " 'TC',\n",
       " 'GACAGT',\n",
       " 'ATT',\n",
       " 'GATCT',\n",
       " 'A',\n",
       " 'AC',\n",
       " 'C',\n",
       " 'GGCATCTC',\n",
       " 'AAT',\n",
       " 'ACTGGGA',\n",
       " 'AAACT',\n",
       " 'AACC',\n",
       " 'TTGTAC',\n",
       " 'AA',\n",
       " 'T',\n",
       " 'AAT',\n",
       " 'AAAA',\n",
       " 'AAACACC',\n",
       " 'GCCT',\n",
       " 'GGCATT',\n",
       " 'GGCCAC',\n",
       " 'GCC',\n",
       " 'GACCC',\n",
       " 'TTGT',\n",
       " 'AAGTTT',\n",
       " 'AGACACC',\n",
       " 'TTCTAGATT',\n",
       " 'GGTGGACC',\n",
       " 'GTTT',\n",
       " 'AGAGGC',\n",
       " 'TGCTT',\n",
       " 'ACGA',\n",
       " 'GAATGC',\n",
       " 'TCT',\n",
       " 'ACCCC',\n",
       " 'GGCGCC',\n",
       " 'AGCAATT',\n",
       " 'GAAC',\n",
       " 'ACGAA',\n",
       " 'ATAC',\n",
       " 'AGAGCC',\n",
       " 'GCCGT',\n",
       " 'G',\n",
       " 'C',\n",
       " 'ATGTCC',\n",
       " 'AGCC',\n",
       " 'AGGGCC',\n",
       " 'AAC',\n",
       " 'AGAGGT',\n",
       " 'GCCTC',\n",
       " 'AGGA',\n",
       " 'GTGGGC',\n",
       " 'GGCC',\n",
       " 'GCCCT',\n",
       " 'AACC',\n",
       " 'AACCGCCT',\n",
       " 'ACCTT',\n",
       " 'TCC',\n",
       " 'ATTT',\n",
       " 'GAGCTT',\n",
       " 'ATAC',\n",
       " 'GGAA',\n",
       " 'G',\n",
       " 'GTCAT',\n",
       " 'GGAA',\n",
       " 'GCCT',\n",
       " 'GAACC',\n",
       " 'TT',\n",
       " 'ACGTC',\n",
       " 'AGGAAT',\n",
       " 'AGGGT',\n",
       " 'A',\n",
       " 'GACACT',\n",
       " 'TCCGCGT',\n",
       " 'ACTAA',\n",
       " 'TCGC',\n",
       " 'ATCCCCTT',\n",
       " 'GTTC',\n",
       " 'ATTTGGC',\n",
       " 'GAT',\n",
       " 'GGCGACC',\n",
       " 'AACT',\n",
       " 'GGGACC',\n",
       " 'ACTCGGA',\n",
       " 'GTTT',\n",
       " 'GGC',\n",
       " 'TCAATC',\n",
       " 'ACAT',\n",
       " 'AGCAT',\n",
       " 'GGTC',\n",
       " 'TCTAT',\n",
       " 'GC',\n",
       " 'ACAC',\n",
       " 'AAATC',\n",
       " 'AC',\n",
       " 'AACAC',\n",
       " 'ACCC',\n",
       " 'TTT',\n",
       " 'GAAC',\n",
       " 'AACGCCAAT',\n",
       " 'AAGT',\n",
       " 'AGCAA',\n",
       " 'GGCGC',\n",
       " 'ATAC',\n",
       " 'ACCGA',\n",
       " 'GGTCTCT',\n",
       " 'AGGAC',\n",
       " 'ATGCT',\n",
       " 'GACC',\n",
       " 'AGAT',\n",
       " 'ATATT',\n",
       " 'GT',\n",
       " 'ATTAC',\n",
       " 'AATAA',\n",
       " 'AGCTT',\n",
       " 'ACACGT',\n",
       " 'AG']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "test_text = \"\".join([random.choice(\"ATCG\") for _ in range(1000)])\n",
    "\n",
    "s.encode(test_text, out_type=str, enable_sampling=True, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_lm_spp_fwd = (TextList.from_folder(path, processor=[OpenFileProcessor(), SPProcessor()])\n",
    "#                  .split_by_rand_pct(0.1, seed=42)\n",
    "#                  .label_for_lm()\n",
    "#                  .databunch(bs=128, num_workers=4))\n",
    "#data_lm_spp_fwd.show_batch()\n",
    "#parent_dir = Path('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes')\n",
    "#path_to_files = parent_dir / 'genome_fastas'\n",
    "#with open(parent_dir / 'all_files_merged.txt', 'w'):\n",
    "#    pass\n",
    "#\n",
    "#files  = set()\n",
    "#for file in path_to_files.iterdir():\n",
    "#    files.add(file)\n",
    "#genome = SeqIO.parse('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/bacterial_genomes/genome_fastas/Corynebacterium striatum.fna', 'fasta')\n",
    "#chroms = [GB for GB in genome if 'chromosome' in GB.description] #  remove plasmid\n",
    "#genome = ''.join([i.seq.__str__() for i in chroms]).upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gen_sp =  SPProcessor()\n",
    "#data = (TextList.from_folder(parent_dir, processor=[OpenFileProcessor(), gen_sp])\n",
    "#        .split_by_rand_pct(0.1, seed=42)\n",
    "#        .label_for_lm()\n",
    "#        .databunch(bs=128, num_workers=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = f.read()\n",
    "#x = x.replace('\\n', '')\n",
    "#x = x[67:]\n",
    "#with open('test.txt', 'w') as f:\n",
    "#    f.write(x)\n",
    "\n",
    "#import random\n",
    "#import youtokentome as yttm\n",
    "\n",
    "#train_data_path = \"test.txt\"\n",
    "#model_path = \"example.model\"\n",
    "\n",
    "# Generating random file with training data\n",
    "# 10000 lines with 100 characters in each line\n",
    "#n_lines = 10000\n",
    "#n_characters = 100\n",
    "#with open(train_data_path, \"w\") as fout:\n",
    "#    for _ in range(n_lines):\n",
    "#        print(\"\".join([random.choice(\"abcd \") for _ in range(n_characters)]), file=fout)\n",
    "\n",
    "\n",
    "# Training model\n",
    "#yttm.BPE.train(data=train_data_path, vocab_size=5000, model=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "#bpe = yttm.BPE(model=model_path)\n",
    "\n",
    "# Generating random text\n",
    "#test_text = \"\".join([random.choice(\"ATCG\") for _ in range(100)])\n",
    "\n",
    "# Two types of tokenization\n",
    "#print(bpe.encode([test_text], output_type=yttm.OutputType.ID))\n",
    "#print(bpe.encode([test_text], output_type=yttm.OutputType.SUBWORD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0,100):\n",
    "#    print(bpe.id_to_subword(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bpe.vocab_size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (genomic_ulmfit)",
   "language": "python",
   "name": "genomic_ulmfit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
