{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. coli Promoter Classification with Genomic Pretraining\n",
    "\n",
    "This notebook builds on the previous one. Here, we show how using the [ULMFiT](https://arxiv.org/abs/1801.06146) technique of pretraining the classification model as a language model significantly improves performance. \n",
    "\n",
    "The \"language model\" here is a genomic prediction model. Given a sequence of input genomic tokens, the model outputs predictions of what token will be next. As described in the previous notebook, the genomic sequence will be represented by 5bp tokens with a stride of 2 between tokens.\n",
    "\n",
    "This allows us to train a model that learns representations of genomic tokens in a totally unsupervised way. The key difference that makes this technique different from previous methods that leverage pretraining for genomic classification (see [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6020378/), [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5954283/) and [here](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6189047/)) is we use a large, unlabeled genomic corpus. Previous implementations of unsupervised pre-training train on only the classification corpus or a synthetically generated corpus of sequences similar to the classification corpus. These methods limit the pre-training corpus by the user's ability to gather labeled data.\n",
    "\n",
    "Comparatively, the UMLFiT approach allows us to use any large corpus of genomic data, regardless of its relation to the classification data. This allows us to pretrain on more data and generate better models.\n",
    "\n",
    "Once the genomic language model is trained, we can transfer the encoding section of the model (embedding + LSTM layers) to the classification model. This allows us to port over more pretrained weights than just the vector embeddings for the k-mers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "\n",
    "# sets device for model and PyTorch tensors\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3,4,5,6,7\" # \"-1\" if want to run on a CPU, otherwise define the GPU number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import ( BaseTokenizer, Tokenizer, Vocab, \n",
    "                         PreProcessor, ItemList, PathOrStr, \n",
    "                         DataFrame, Optional, Collection, \n",
    "                         IntsOrStrs, DataBunch, is_listy, \n",
    "                         ItemLists, TextList, SortishSampler, \n",
    "                         DataLoader, SortSampler, partial, \n",
    "                         pad_collate, TextLMDataBunch, data_collate, \n",
    "                         LanguageModelPreLoader )\n",
    "from Bio import Seq\n",
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "from Bio.SeqFeature import FeatureLocation, CompoundLocation\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")\n",
    "from utils import ( _get_genomic_processor, get_model_clas, TextClasDataBunch, \n",
    "                    get_scores, split_data, GenomicTokenizer, get_model_LM, \n",
    "                   GenomicVocab, GenomicTextClasDataBunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/ecoli/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path/'e_coli_lm_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The language model data is just long strings of genomic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sequence</th>\n",
       "      <th>is_train</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATT...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GGTTTCACCGCCGGTAATGAAAAAGGCGAACTGGTGGTGCTTGGAC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AGCTGGCTGAAGAATAAACATATCGACTTACGTGTCTGCGGTGTTG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCGTTGGTACTGCGCGGATATGGTGCGGGCAATGACGTTACAGCTG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CGCTCTGTGTGACAAGCCGGAAACCGCCCAGCGCGTTGCCGACTGG...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sequence  is_train\n",
       "0  AGCTTTTCATTCTGACTGCAACGGGCAATATGTCTCTGTGTGGATT...         1\n",
       "1  GGTTTCACCGCCGGTAATGAAAAAGGCGAACTGGTGGTGCTTGGAC...         1\n",
       "2  AGCTGGCTGAAGAATAAACATATCGACTTACGTGTCTGCGGTGTTG...         1\n",
       "3  CCGTTGGTACTGCGCGGATATGGTGCGGGCAATGACGTTACAGCTG...         1\n",
       "4  CGCTCTGTGTGACAAGCCGGAAACCGCCCAGCGCGTTGCCGACTGG...         1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10% of the data used for validation\n",
    "train_df, valid_df = split_data(df, 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and Numericalization\n",
    "\n",
    "The tokenization functions are the same as those described in the previous notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer(GenomicTokenizer, n_cpus=1, pre_rules=[], post_rules=[], special_cases=['xxpad'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "\n",
    "To create our dataloader, we use a slightly different variant of the classification dataloader. The `GenomicTextLMDataBunch` class sets up the data with a language model structure, where the correct y value for each token is the next sequential token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenomicTextLMDataBunch(TextLMDataBunch):\n",
    "    @classmethod\n",
    "    def from_df(cls, path:PathOrStr, train_df:DataFrame, valid_df:DataFrame, test_df:Optional[DataFrame]=None,\n",
    "                tokenizer:Tokenizer=None, vocab:Vocab=None, classes:Collection[str]=None, text_cols:IntsOrStrs=1,\n",
    "                label_cols:IntsOrStrs=0, label_delim:str=None, chunksize:int=10000, max_vocab:int=60000,\n",
    "                min_freq:int=2, mark_fields:bool=False, bptt=70, collate_fn:Callable=data_collate, bs=64, **kwargs):\n",
    "        \"Create a `TextDataBunch` from DataFrames. `kwargs` are passed to the dataloader creation.\"\n",
    "        processor = _get_genomic_processor(tokenizer=tokenizer, vocab=vocab, chunksize=chunksize, max_vocab=max_vocab,\n",
    "                                   min_freq=min_freq, mark_fields=mark_fields)\n",
    "        if classes is None and is_listy(label_cols) and len(label_cols) > 1: classes = label_cols\n",
    "        src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),\n",
    "                        TextList.from_df(valid_df, path, cols=text_cols, processor=processor))\n",
    "        src = src.label_for_lm() \n",
    "        if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))\n",
    "        d1 = src.databunch(**kwargs)\n",
    "        \n",
    "        datasets = cls._init_ds(d1.train_ds, d1.valid_ds, d1.test_ds)            \n",
    "        val_bs = bs\n",
    "        datasets = [LanguageModelPreLoader(ds, shuffle=(i==0), bs=(bs if i==0 else val_bs), bptt=bptt, backwards=False) \n",
    "                    for i,ds in enumerate(datasets)]            \n",
    "        dls = [DataLoader(d, b, shuffle=False) for d,b in zip(datasets, (bs,val_bs,val_bs,val_bs)) if d is not None]\n",
    "        \n",
    "        return cls(*dls, path=path, collate_fn=collate_fn, no_check=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = GenomicTextLMDataBunch.from_df(path, train_df, valid_df, bs=428, tokenizer=tok, text_cols=0, label_cols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model vocabulary - 1025 tokens. 1024 5-mer nucleotide combinations plus one padding token\n",
    "len(data.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Text [680 198  57 337 ... 492  42  25 128], EmptyLabel 0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we save the `itos` list from the dataloader as a numpy array. This is extremely important. When we transfer the pretrained weights from the language model to the classification model, we need to ensure the mapping from k-mers to integer ids is the same. Otherwise the embedding will be completely scrambled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path/'coli_vocab.npy', data.vocab.itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Model\n",
    "\n",
    "The configuration of the language model is very similar to the classification model. This is because we need the sizes of the embedding and LSTM layers in the language model to match those we want in the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=0, qrnn=False, output_p=0.25, \n",
    "                          hidden_p=0.1, input_p=0.2, embed_p=0.02, weight_p=0.15, tie_weights=True, out_bias=True)\n",
    "drop_mult = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_model_LM(data, drop_mult, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): AWD_LSTM(\n",
       "    (encoder): Embedding(1025, 400, padding_idx=0)\n",
       "    (encoder_dp): EmbeddingDropout(\n",
       "      (emb): Embedding(1025, 400, padding_idx=0)\n",
       "    )\n",
       "    (rnns): ModuleList(\n",
       "      (0): WeightDropout(\n",
       "        (module): LSTM(400, 1150, batch_first=True)\n",
       "      )\n",
       "      (1): WeightDropout(\n",
       "        (module): LSTM(1150, 1150, batch_first=True)\n",
       "      )\n",
       "      (2): WeightDropout(\n",
       "        (module): LSTM(1150, 400, batch_first=True)\n",
       "      )\n",
       "    )\n",
       "    (input_dp): RNNDropout()\n",
       "    (hidden_dps): ModuleList(\n",
       "      (0): RNNDropout()\n",
       "      (1): RNNDropout()\n",
       "      (2): RNNDropout()\n",
       "    )\n",
       "  )\n",
       "  (1): LinearDecoder(\n",
       "    (decoder): Linear(in_features=400, out_features=1025, bias=True)\n",
       "    (output_dp): RNNDropout()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is trained using the same learning rate/momentum scheduling described in the previous notebook.\n",
    "\n",
    "#### A note on language model performance\n",
    "\n",
    "If you decide to play around with different genomes, different k-mer sizes or strides, there are some important things to know about comparing performance between models. We measure performance via cross entropy loss and accuracy. These values are strongly influenced by the stride of the k-mers.\n",
    "\n",
    "Consider our stride 2 case. Any k-mer XXABC will be followed by a k-mer of the form ABCXX. The model quickly learns this mapping and places equal probability over all k-mers of the ABCXX form. For a stride of 2 (XX), this comes out to 16 (4^2) possible k-mers. I consider this point the baseline \"random guessing\" model that has only learned the most basic, obvious mapping encoded in the data. I think performance of these models should be measured relative to this baseline.\n",
    "\n",
    "We can relate the number of possible \"informed random guesses\" to the expected perplexity/cross entropy of the model. If we assume that each k-mer is equally distributed in the dataset and each of the 16 possible ABCXX k-mers is given equal proability by the model, we would expect the model's perplexity to be 16 and the cross entropy to be ln(16)=2.77.\n",
    "\n",
    "If you look at the validation loss of the model printed below, you can see it quickly trains down to a loss of around 2.7, then struggles to get lower. The model trains to a final validation loss of 2.63. This is to say the language model below is only slightly better than \"informed random\". However as we will see, this is more than enough to see a significant improvement in classification performance.\n",
    "\n",
    "Understanding the relationship between stride and the \"informed random\" baseline is important for comparing models that use different stride values. If a model has a stride of 1, we expect an \"informed random\" mapping of XABCD --> ABCDX. This would give an expected perplexity of 4 and a cross entropy of ln(4) = 1.38. This means that a stride 1 model with a loss of 1.38 is performing comprably to a stride 2 model with a loss of 2.77.\n",
    "\n",
    "Similarly for stride 3 models, we expect an \"informed random\" perplexity of 64 and a cross entropy of 4.15. Don't be fooled by the stride effect on apparent language model performance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 02:02<02:02]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.896128</td>\n",
       "      <td>#na#</td>\n",
       "      <td>02:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='29' class='' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      41.43% [29/70 00:47<01:07 8.7625]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3hcV3nv8e87o5sly7Z8v8h3bCdOiC9RnOtxEtJAnJIbCRCgEDgJxiVA8/ShpykthfZwzoFzOFCgKSalQPO0JDQpPpiSOlxKYtKQYDlxHNuJHd8t27FlS7LsGVmjmXnPH7Nlj+SRLdvac5F/nyfzaPbaa89+ZzLWq7XW3muZuyMiItJbpNABiIhIcVKCEBGRnJQgREQkJyUIERHJSQlCRERyKit0AANp9OjRPm3atEKHISJSMtauXXvI3cfk2jeoEsS0adNobGwsdBgiIiXDzHb1tS+0LiYzm2Nm67Ie7Wb2UK86HzKz9cHjBTObl7XvFjPbbGZbzezhsOIUEZHcQmtBuPtmYD6AmUWBvcCKXtV2ANe7e6uZLQEeBa4M6j8C3Aw0AWvMbKW7bworXhER6Slfg9Q3AdvcvUdTxt1fcPfWYPNFoD54vgjY6u7b3T0BPAHckadYRUSE/CWIe4HHz1DnfuDfg+eTgD1Z+5qCslOY2VIzazSzxubm5vMOVEREMkJPEGZWAdwOPHmaOjeSSRB/2l2Uo1rOSaPc/VF3b3D3hjFjcg7Ei4jIOcjHVUxLgJfd/UCunWZ2GfBdYIm7Hw6Km4DJWdXqgX2hRikiIj3ko4vpA/TRvWRmU4AfAx929y1Zu9YAs8xsetACuRdYGXqkIiJyQqgJwsyqyVyJ9OOssmVmtizY/EtgFPB3waWwjQDungQ+BTwDvA78i7tvDDNWEZFS9ItNB1j+3LZQXjvULiZ3j5NJANlly7OePwA80MexTwNPhxmfiEip++WmAzy75SDLrp854K+tuZhEREpYvCtFdUU4f+srQYiIlLB4Z5Lqimgor60EISJSwmKJJDVqQYiISG8diRRD1IIQEZHeYokUNZVKECIi0ku8M8mQcnUxiYhIL/EutSBERCSHeKcucxURkV66UmkSqbQucxURkZ7iiRSAEoSIiPQUTyQBqKlUF5OIiGRRC0JERHKKd3YnCLUgREQkS6y7i0ktCBERydYRdDFpqg0REekhpkFqERHJ5eQYhFoQIiKSpfsyVw1Si4hIDzFd5ioiIrl0JFJEDCrLwvlVrgQhIlKiuleTM7NQXl8JQkSkRMU7U1SHNNU3KEGIiJSseFd4U31DiAnCzOaY2bqsR7uZPdSrzkVm9lsz6zSzz/bat9PMXguObQwrThGRUhXvTIY2QA0QWupx983AfAAziwJ7gRW9qrUAnwHu7ONlbnT3Q2HFKCJSyrrHIMKSry6mm4Bt7r4ru9DdD7r7GqArT3GIiAwaHYlUaNNsQP4SxL3A42d5jAM/N7O1Zra0r0pmttTMGs2ssbm5+byCFBEpJbFEeOtRQx4ShJlVALcDT57lode6+0JgCfCgmS3OVcndH3X3BndvGDNmzHlGKyJSOjoSJTpInWUJ8LK7Hzibg9x9X/DzIJmxi0UhxCYiUrJiiXAHqfORID7AWXYvmVmNmdV2PwfeCWwIITYRkZIV7wy3BRHeKwNmVg3cDHwiq2wZgLsvN7PxQCMwDEgHl8HOBUYDK4K7A8uAH7r7qjBjFREpJV2pNIlUOrTFgiDkBOHucWBUr7LlWc/fAupzHNoOzAszNhGRUhYPebEg0J3UIiIlKR7yYkGgBCEiUpLiIU/1DUoQIiIl6eRqcmpBiIhIlhPrUasFISIi2To0SC0iIrnENEgtIiK5aJBaRERyindmWhAapBYRkR5iakGIiEguHYkU0YhRWRber3ElCBGREhRLJKkujxLMWRcKJQgRkRIU70xRHeJiQaAEISJSkuJdqVDXowYlCBGRkhTvTIZ6kxwoQYiIlKR4Qi0IERHJIZ5QC0JERHKIJVLUaJBaRER660iEux41KEGIiJSkWCIZ6l3UoAQhIlKS4p1qQYiISC9dqTSJVDrUxYJACUJEpOTE87BYEChBiIiUnHgeFguCEBOEmc0xs3VZj3Yze6hXnYvM7Ldm1mlmn+217xYz22xmW83s4bDiFBEpNflYLAggtPTj7puB+QBmFgX2Ait6VWsBPgPcmV0Y1H8EuBloAtaY2Up33xRWvCIipSLe2Z0gSrQF0ctNwDZ335Vd6O4H3X0N0NWr/iJgq7tvd/cE8ARwR35CFREpbie6mAbJGMS9wONnUX8SsCdruykoExG54A2aQWozqwBuB548m8NylHkfr7/UzBrNrLG5uflcQhQRKSmxUh+kzrIEeNndD5zFMU3A5KztemBfroru/qi7N7h7w5gxY84jTBGR0pCvQep8JIgPcHbdSwBrgFlmNj1ogdwLrBzwyERESlC8M9OCCHuQOtRXN7NqMlcifSKrbBmAuy83s/FAIzAMSAeXwc5193Yz+xTwDBAFvufuG8OMVUSkVMRK/TJXAHePA6N6lS3Pev4Wme6jXMc+DTwdZnwiIqWoI5EiGjEqy8LtBNKd1CIiJSaWSFJdHsUs1/U8A0cJQkSkxMQ7U1SHvFgQKEGIiJSceFf461GDEoSISMmJd4a/HjUoQYiIlJx4Qi0IERHJIZ5IagxCREROFUukQr8HApQgRERKTkci/PWoQQlCRKTkxBJJtSBERORU8U61IEREpJeuVJpEKh36YkGgBCEiUlLytVgQKEGIiJSUjiBBhL1YEChBiIiUlO7V5DRILSIiPcQ7u9eCUAtCRESytB/vAqC2SglCRESytMYTAIysqQj9XEoQIiIlpDWWSRB11UoQIiKSpTWe6WIaUV0e+rmUIERESkhLLEFtVRnl0fB/fStBiIiUkLZ4Ii/dS6AEISJSUlriXdTlYYAalCBEREpKpgUR/vgDKEGIiJSUlliCkaXexWRmc8xsXdaj3cwe6lXHzOybZrbVzNab2cKsfTvN7LXg2Maw4hQRKSVt8S5G5ClBhHYrnrtvBuYDmFkU2Aus6FVtCTAreFwJfDv42e1Gdz8UVowiIqUkkUxzrDNZXF1MZlZjZpHg+Wwzu93MzibCm4Bt7r6rV/kdwGOe8SIwwswmnMXriohcMNqCu6iLbZB6NVBlZpOAXwEfA35wFue5F3g8R/kkYE/WdlNQBuDAz81srZkt7euFzWypmTWaWWNzc/NZhCQiUlpa4vm7ixr6nyDM3ePAe4BvuftdwNx+HWhWAdwOPJlrd44yD35e6+4LyXRDPWhmi3O9vrs/6u4N7t4wZsyY/oQkIlKSWmOZu6jraoqoi4nMePLVwIeAnwVl/R2/WAK87O4HcuxrAiZnbdcD+wDcvfvnQTJjF4v6eT4RkUGptUhbEA8BfwascPeNZjYD+HU/j/0AubuXAFYCHwmuZroKOOLu+4Mxj1rIjH8A7wQ29PN8IiKDUj5ncoV+tgLc/TngOYBgsPqQu3/mTMeZWTVwM/CJrLJlwWsuB54GbgW2AnEyYxsA44AVZtYd4w/dfVX/3pKIyODUPZNrPibqg34mCDP7IbAMSAFrgeFm9jV3/z+nOy4YtxjVq2x51nMHHsxx3HZgXn9iExG5ULTGu6ipiFJZFv5yo9D/Lqa57t4O3Enmr/4pwIdDi0pERE7RGkvk7SY56H+CKA/ue7gT+Im7d3HyaiMREcmD1ngib+MP0P8E8R1gJ1ADrDazqUB7WEGJiMipWuJdeRt/gH4mCHf/prtPcvdbg7uedwE3hhybiIhkaSvGFoSZDTezr3XfsWxm/5dMa0JERPKkJZa/xYKg/11M3wOOAu8LHu3A98MKSkREeupKpTl6PJnXBNHfu6FnuvvdWdt/ZWbrwghIRERO1RbP7zQb0P8WRIeZXde9YWbXAh3hhCQiIr215XmaDeh/C2IZ8JiZDQ+2W4H7wglJRER6a4kVaYJw91eBeWY2LNjuXh1ufZjBiYhIRmsRdzEBmcQQ3FEN8MchxCMiIjkUoovpfNakzrWWg4iIhCDfiwXB+SUITbUhIpInbfEuqsojDKnIz0R9cIYxCDM7Su5EYMCQUCISEZFTtMQSjMxj6wHOkCDcvTZfgYiISN/a4vmdyRXOr4tJRETypCWWyOsVTKAEISJSEtriXXkdoAYlCBGRktASz+9EfaAEISJS9FJp50hHF3V5nOoblCBERIrekY4u3KEuj4sFgRKEiEjRaw1uksvnYkGgBCEiUvRag4n6dJmriIj00D1RX75vlAstQZjZHDNbl/XongE2u46Z2TfNbKuZrTezhVn7bjGzzcG+h8OKU0Sk2J1sQeR3DKK/60GcNXffDMwHMLMosBdY0avaEmBW8LgS+DZwZVD/EeBmoAlYY2Yr3X1TWPGKiBSrwT4GcROwzd139Sq/A3jMM14ERpjZBGARsNXdt7t7AngiqCsicsFpiSeoiEaozuNEfZC/BHEv8HiO8knAnqztpqCsr/JTmNlSM2s0s8bm5uYBCldEpHi0xbqoqynHLL+rLISeIMysArgdeDLX7hxlfpryUwvdH3X3BndvGDNmzLkHKiJSpApxFzWEOAaRZQnwsrsfyLGvCZictV0P7AMq+igXEbngtBUoQeSji+kD5O5eAlgJfCS4mukq4Ii77wfWALPMbHrQArk3qCsicsE5HEvkfYAaQk4QZlZN5kqkH2eVLTOzZcHm08B2YCvw98AnAdw9CXwKeAZ4HfgXd98YZqwiIsXI3dnX1sHEEVV5P3eoXUzuHgdG9SpbnvXcgQf7OPZpMglEROSCdehYguNdaerrqvN+bt1JLSJSxJpa4wDU1+V/lWclCBGRItbU2gGgFoSIiPTUnSAmqQUhIiLZmlrj1FWXM7QyH3cl9KQEISJSxJpaOwrSvQRKECIiRa2pNV6QAWpQghARKVruHrQglCBERCRL87FOOpOFuQcClCBERIpW9xVMk0eqBSEiIlkKeQ8EKEGIiBSt7ruoJ41QC0JERLI0tXYwsqaCmgLcAwFKECIiRauQVzCBEoSISNEq5D0QoAQhIlKU3J29BbyLGpQgRESK0sl7INSCEBGRLHtaui9xVYIQEZEs3Ze4TlYXk4iIZCvkOhDdlCBERIpQU2sHo2oqqK4ozD0QoAQhIlKUCn2JKyhBiIgUpUJf4gpKECIiRSeddpraCnsXNShBiIgUnUPHOkkU+B4ICDlBmNkIM3vKzN4ws9fN7Ope++vMbIWZrTez35nZpVn7dprZa2a2zswaw4xTRKSY7CnwNN/dwh4e/wawyt3vMbMKoPe7/Rywzt3vMrOLgEeAm7L23+juh0KOUUSkqHTfAzFoWxBmNgxYDPwDgLsn3L2tV7W5wK+C/W8A08xsXFgxiYiUgh2HYpgV9h4ICLeLaQbQDHzfzF4xs++aWU2vOq8C7wEws0XAVKA+2OfAz81srZkt7eskZrbUzBrNrLG5uXng34WISJ69sruN2WNrC3oPBISbIMqAhcC33X0BEAMe7lXny0Cdma0DPg28AiSDfde6+0JgCfCgmS3OdRJ3f9TdG9y9YcyYMWG8DxGRvEmnnVd2t7Jw6ohChxJqgmgCmtz9pWD7KTIJ4wR3b3f3j7n7fOAjwBhgR7BvX/DzILACWBRirCIiRWFb8zHajydZMKWu0KGElyDc/S1gj5nNCYpuAjZl1wmucqoINh8AVrt7u5nVmFltUKcGeCewIaxYRUSKxcu7WwFYWAQJIuwOrk8D/xwkge3Ax8xsGYC7LwcuBh4zsxSZ5HF/cNw4YIWZdcf4Q3dfFXKsIiIF9/KuNoYPKWfG6N5DtvkXaoJw93VAQ6/i5Vn7fwvMynHcdmBemLGJiBSjl3e3snDKCCIRK3QoupNaRKRYHOno4s2Dx4qiewmUIEREisa6PZlbxRZOVYIQEZEsa3e1EjGYN7nwl7iCEoSISNF4ZXcrs8fVMrSysDfIdSuOKArsyv/5S453pYkYmBkGWI/xIcOMHOU9apyo0xcH3PsfV1/nypwvu55lPQ8eQTzddbvfFwaRrPeYXS9iRiSSKTvxWQT1u7cjJ7Yz+6IRO7EdjRD8NMoiRjQSIRqBaCQSbAflUaM8EqEsapRHI5Sf+BmhIhqhvMyoiEapKItQVR6hqjxKVVn05PPyKEMqolSXR4tiIE9kIKTTzrrdbdw2f2KhQzlBCQK4fd5EEsk0DqTdT/klnnaATLn7qb+43cE59Tjn1ITR/Uv5TJy+M0n2eTyrzHGC//Cgkp/YlykL3sqJ99kd94n9wb50r7JU2nEy5clU5rNKpR13J+VOKp2pm0oHD3eSqZPPU2knmUqTTHvmkUoHn+u5M4OhlWUMqypn2JBy6qrLqaupoK66nIkjhjBlZDVTRlYzdWQNw6vLz+9kIiF78+AxjnYmubxIBqhBCQKAP//9uYUO4YKUTjtd6TTJlNOVSpNIpkmk0nSlnEQyTWcyRWcyTWdXmuNdKY4nU3QkUhzvShFPpDjWmeTo8STtx7to7+iiNd7F6/vbaYklaIt39TjXhOFVXDxhGBdPqGX2uFqmj65h+ugaaquUOKQ4nLhBrkgGqEEJQgooEjEqI1HC6G6NdSbZ0xpn9+E42w/FeGN/O6/vP8rqLc0ks5ouo4dWMnnkEOrrqqmvG0J9XablMbmumokjhlBRpmE6yY+Xd7UysqaCaaMKuwZENiUIGZRqKsu4aPwwLho/rEd5ZzLFrsNxtjfH2HEoxo5Dx2hq7eDVPW2s2rCfrtTJ5BExmDyymllja5k9bihzxtdy+dS6gi/iIoPT2t2tLJg8oseYYqEpQcgFpbIsyuxxmW6m3lJp50D7cfa0xNndEmdPS5xtzTG2HDjKs5sPnmh5TBoxhCunj+S6WaN51yXjqSmSK06kdDUf7WR7c4y7F9afuXIe6ZstEohGjIkjhjBxxBCunDGqx75EMs2bB4/SuLOVl3YcZvWbzfz4lb3UVGzg1rdP4L0Nk2mYWqerquSc/GTdXgBunltc66UpQYj0Q0VZhEsmDueSicO575ppuDuNu1p5snEPP1u/nyfXNjG2tpIb54zlxovGct2s0UVzLbsUv399eS/z6ofnbNkWkr7BIufAzLhi2kiumDaSL95+Cc9sfItfvn6Qp1/bz48a91AeNRqmjmTx7DEsnj2auROGFVXfshSPjfuO8Pr+dv76jksKHcoplCBEzlN1RRl3LajnrgX1dKXSNO5s5dnNB3luSzNfWfUGX1mVucz2lkvH8/tvn8DCKeqKkpOeWttERTTCbZcVzw1y3ZQgRAZQeTTC1TNHcfXMUfzZrRdzsP04q988xDMb3+KfX9rN9/9zJ+OHVfG+hno+eOVUxg+vKnTIUkCJZJqfrNvH780dS11NxZkPyDMlCJEQjR1WxT2X13PP5fUcPd7Fr14/yE/W7eVbv97KI89u412XjOMjV0/jyukj1QV1AXp280FaYgnuuby4rl7qpgQhkie1VeXcuWASdy6YxO7Dcf7ppV38aM0enn7tLS4aX8tHr5nGHfMnMaQiWuhQJU+eWtvE6KGVLJ41ptCh5KTbREUKYMqoaj5368W8+Gc38ZW73w7Awz9+jau//Cu+9G+b2HrwaIEjlLAdPtbJf7xxkLsWTKQsWpy/itWCECmgIRVR3n/FFN7XMJmXdrTw2G938oMXdvLd53fQMLWO918xmdvmTaSqXK2KwWblq/tIpp27i7R7CcD8bOafLnINDQ3e2NhY6DBEzkvz0U5WvNLEE2v2sL05xojqct7fMJk/uGoqk0dqmo/B4HhXipu//hx11RWs/NR1BY3FzNa6e0OufWpBiBSZMbWVLF08k4//lxknWhXffX4Hj/5mOzddNJaPXjOda982SoPaJWz5c9vY09LBV+6+rNChnJYShEiRMjOumjGKq2aMYv+RDv75xd08/rvd/PL1l3jb2KHcd8007llYr0HtErOnJc63n93Guy+bwDUzRxc6nNMqzpEREelhwvAhfPZdc/jPh9/BV987j6ryCJ//fxu44au/5ocv7SaZShc6ROmnv/63TUQjxp///sWFDuWMQk0QZjbCzJ4yszfM7HUzu7rX/jozW2Fm683sd2Z2ada+W8xss5ltNbOHw4xTpFRUlUe55/J6fvqp63hi6VVMGjGEz614jXd+fTWrNuxnMI0pDka/3nyQX2w6wKffMYsJw4cUOpwzCrsF8Q1glbtfBMwDXu+1/3PAOne/DPhIUB8ziwKPAEuAucAHzEzLvokEuruf/vUPr+HRD19ONGIs+6eX+fTjr3Ck12p6Uhw6kyn+auVGZoyu4f7rphc6nH4JLUGY2TBgMfAPAO6ecPe2XtXmAr8K9r8BTDOzccAiYKu7b3f3BPAEcEdYsYqUKjPjnZeMZ9VDi/mTd81h1Ya3WPKN1fx22+FChyZZOpMp/ujxdew8HOcLt19SMisVhjlIPQNoBr5vZvOAtcAfuXssq86rwHuA581sETAVqAcmAXuy6jUBV+Y6iZktBZYCTJkyZaDfg0hJiEaMB298G9e9bTQP/WgdH/zui1w5fSSVZVHKIkZleYQrpo3k5rnjtCJennUkUnzin9ayekszn3/3XK6fXZx3TecS2n0QZtYAvAhc6+4vmdk3gHZ3/3xWnWFkupUWAK8BFwEPALOBd7n7A0G9DwOL3P3Tpzun7oMQyazH/dWfb2Z90xGSaSeVTtPekWR3SxyASyYO47L64Rw6luBA+3EOtnfiODWVZQwNHnXVFdTVlDOyugLMaD7amXkc66SzK0VXKn1iedaayjJqK8sYWlXG+OFVzBo7lFlja5k1bihjaysv6Mtxjx7v4v4fNLJmVwtffs/bef8VxfdHbKHug2gCmtz9pWD7KaDHYLO7twMfC4I0YEfwqAYmZ1WtB/aFGKvIoFFTWcYXbjt1bYEdh2L8YtNbPLPxAM9sPMDY2krGDqtizrhaImYcSySJdSY5ejzJG2+10xrvojWeAGBUTQWjh1YypraSIbWVlJdFKA+mLD/WmeJYZxcH2o+zdlcrRzpOjoGMqqng0knDuXTSMObVj+DqmaOorSrPzwdRYFsOHOWhJ9ax5cBRvnnvAm6bV3zTeZ9JaAnC3d8ysz1mNsfdNwM3AZuy65jZCCAejDM8AKx293YzWwPMMrPpwF7gXuCDYcUqciGYPrqGpYtnsnTxzH4fk0o77t7vuYLcnUPHErx58Chb3jrKxn3tbNjXznee204y7ZRFjMun1nH9nDHcMHssF0+oHXQtjK5Umm8/u41v/ceb1FaV8/f3NXDjnLGFDuuchDrVhpnNB74LVADbybQW3g/g7suDy14fA1Jkksf97t4aHHsr8DdAFPieu/+PM51PXUwixel4V4pXdrex+s1mntvczKb97QCMG1bJDbPHcv2cMSyYMoLxw6pKNmGk084L2w7zpZ9t4o23jnL7vIl84ba5jBpaWejQTut0XUyai0lE8u5g+3Ge29LMs5ubWb2lmaOdSSAzzchlk4ZzyaThzBo7lNnjapk+uqaor/ppPtrJU2ubeGLNbnYdjjNuWCVfuvPt3Dx3XKFD6xclCBEpWl2pNOubjvBaUxvrm47walMbOw7FSAe/mqIRY3LdEKaOqmH66Bqmjapm2ugaZoweyqS6IUTzvHxr+/Eu1u5q5cXth3lxewsb9h4hlXYWTR/JBxdN4ZZLx5fU7LuarE9EilZ5NMLlU+u4fGrdibLjXSm2NR9j68FjbDlwlJ2H4uw8HKNxZwuxRCrrWGNyXTVTRlUzZWTmMXZYFWNrKxk3rIqRNRXUVETPar2FzmSKtmCAvjXWRVs8wd62DjbsPcL6vUfY3hw7ce75k0fwyRtmcsf8Sbxt7NCB+1CKhBKEiBSdqvIol0wcziUTh/cod3eaj3VmEsahGNsPxdjdEmPX4Thrd7ae6KrqrbIsQk1lGREzwOnuOCmLGuXRCOXRCIlkmrZ4okcCyjZ+WBVvrx/OXfMnsWBKJqEN9okSlSBEpGSYGWNrqxhbW8Wi6SN77HN3jnR0caA9c8/GwaPHaYkliHWmiCeSxBJJUmkwg+5OqWTKM/d0BFdY1VVXUFddzoiaCkYGz+tqKhhTW8noIh9sDoMShIgMCmbGiOoKRlRXMGd8baHDGRSK99IAEREpKCUIERHJSQlCRERyUoIQEZGclCBERCQnJQgREclJCUJERHJSghARkZwG1WR9ZnYEeDPHruHAkX5udz/PVTYaOHSWYfU+V3/35yrPFVNfz88n5tPF1d/4SiXmXOWl+P3oT8zZz/X96P/+wf79mOXuPec06ebug+YBPNqf8tNtdz/vo6xxoGI625j7iulM8Z9LzOcadynGPFi+H/2JudCftb4fxf/96P0YbF1MP+1n+em2f3qasoGM6Uz7c5X3FdOZ4j8X5xJ3Kcacq7wUvx/9iTn7ub4f/d9/IX0/ehhUXUxhM7NG72Pe9GKlmPOnFONWzPlTinEPthZE2B4tdADnQDHnTynGrZjzp+TiVgtCRERyUgtCRERyUoIQEZGcLtgEYWbfM7ODZrbhHI693MxeM7OtZvZNM7Osfe8zs01mttHMfljsMZvZR82s2czWBY8Hij3mrP33mJmb2YAO/IX0OS8LyteZ2fNmNncgYw4x7j8Ovs/rzexXZja1BGJebGYvm1nSzO4phlj7eL37zOzN4HFfVvl0M3spKP+RmVUMxPnOyblcTzwYHsBiYCGw4RyO/R1wNZmVC/8dWBKUzwJeAeqC7bElEPNHgb8tpc852FcLrAZeBBqKPWZgWFad24FVpfBZAzcC1cHzPwR+VAIxTwMuAx4D7il0rMCzwLReZSOB7cHPuuB59++NfwHuDZ4vB/5woL8r/X1csC0Id18NtGSXmdlMM1tlZmvN7DdmdlHv48xsApl/7L/1zP/Bx4A7g90fBx5x99bgHAdLIOZQhRjzfwf+N3C8FGJ29/asqjXAgF8dElLcv3b3eFD1RaC+BGLe6e7rgXQxxNqHdwG/cPeW4PfFL4BbglbQO4Cngnr/SJ7+reZywSaIPjwKfNrdLwc+C/xdjjqTgKas7aagDGA2MNvM/tPMXjSzW0KNNuN8Ywa4O+hCeMrMJk3CWN4AAAVCSURBVIcX6gnnFbOZLQAmu/u/hR1olvP+nM3sQTPbRiaxfSbEWLMNxPej2/1k/lIP20DGHLb+xJrLJGBP1nZ3/KOANndP9ioviLJCnbjYmNlQ4Brgyayu7spcVXOUdf81WEamm+kGMn9p/cbMLnX3toGNNghkYGL+KfC4u3ea2TIyf7G8Y6BjPRHIecZsZhHg62S6xvJigD5n3P0R4BEz+yDwF8B9OeoPmIGKO3itPwAagOsHMsZTAhnAmMN2uljN7GPAHwVlbwOeNrMEsMPd76Lv+Av+vrIpQZwUIZO552cXmlkUWBtsrgS+Tc9mdj2wL3jeBLzo7l3ADjPbTCZhrCnWmN39cFb53wNfCSnWbucbcy1wKfBs8I9yPLDSzG5398Yijbm3J4K6YRuQuM3s94A/B653985QIx74zzpMOWMFcPfvA98HMLNngY+6+86sKk1k/pDsVk9mrOIQMMLMyoJWRCHe10mFGvwohgeZwawNWdsvAO8Nnhswr4/j1gBXcXJw7Nag/BbgH4Pno8k0IUcVecwTsurcRSbBFfXn3KvOswzwIHVIn/OsrDq3cY4TzhUg7gXAtuz4iz3mrP0/YAAHqc81VvoepN5BZoC6Lng+Mtj3JD0HqT8Z1md/xvdbqBMX+gE8DuwHushk8/uB6cAq4FVgE/CXfRzbAGwI/uH8LSfvSDfga8Gxr3X/Ty7ymP8XsDE4/tfARcUec686zzLwVzGF8Tl/I/ic1wWf8yUl8p3+JXAgiHsdsLIEYr4ieK0YcBjYWMhYyZEggvL/CmwNHh/LKp9B5gqtrWSSReVAf1f6+9BUGyIikpOuYhIRkZyUIEREJCclCBERyUkJQkREclKCEBGRnJQgZFAzs2N5Pt8LA/Q6N5jZETN7xczeMLOv9uOYOy2EWWLlwqUEIXIWzOy0sw+4+zUDeLrfuPsCMjervdvMrj1D/TsBJQgZMJpqQy44ZjYTeAQYA8SBj7v7G2Z2G5k5kirI3GD1IXc/YGZfBCaSuYv2kJltAaaQuaFpCvA37v7N4LWPuftQM7sB+CKZqRMuJTNNxB+4u5vZrWRuqDwEvAzMcPd39xWvu3eY2TpOTlb4cWBpEOdW4MPAfDLTiF9vZn8B3B0cfsr7PI+PTi4wakHIhaivGTifB64K/mp/AvhvWcdcDtzh7h8Mti8iM2XzIuALZlae4zwLgIfI/FU/A7jWzKqA75BZu+A6Mr+8T8vM6sjM6bU6KPqxu1/h7vOA14H73f0FMnMU/Ym7z3f3bad5nyL9ohaEXFDOMFtoPfCjYK2BCjLz43Rb6e4dWds/88zEdZ1mdhAYR8/ppwF+5+5NwXnXkWmBHAO2u3v3az9OpjWQy38xs/XAHODL7v5WUH6pmX0JGAEMBZ45y/cp0i9KEHKh6XMGTuBbwNfcfWVWF1G3WK+62bOapsj9bylXnVzTOfflN+7+bjObDTxvZivcfR2ZSejudPdXzeyj9JwVtNvp3qdIv6iLSS4onlnZbYeZvRfAMuYFu4cDe4PnYa3V8AYww8ymBdvvP9MB7r6FzKSKfxoU1QL7g26tD2VVPRrsO9P7FOkXJQgZ7KrNrCnr8cdkfqneb2avkplh9Y6g7hfJdMn8hswA8oALuqk+Cawys+fJzJR6pB+HLgcWm9l04PPAS2SWqcwedH4C+JPg0tiZ9P0+RfpFs7mK5JmZDXX3Y8H6w48Ab7r71wsdl0hvakGI5N/Hg0HrjWS6tb5T4HhEclILQkREclILQkREclKCEBGRnJQgREQkJyUIERHJSQlCRERy+v99S8+tBa73rQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>6.364583</td>\n",
       "      <td>5.480070</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.761972</td>\n",
       "      <td>3.138015</td>\n",
       "      <td>0.099320</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.383558</td>\n",
       "      <td>2.769874</td>\n",
       "      <td>0.109467</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.920902</td>\n",
       "      <td>2.740448</td>\n",
       "      <td>0.113201</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.795075</td>\n",
       "      <td>2.726324</td>\n",
       "      <td>0.117565</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.755662</td>\n",
       "      <td>2.720301</td>\n",
       "      <td>0.120139</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.728018</td>\n",
       "      <td>2.680003</td>\n",
       "      <td>0.131442</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.699944</td>\n",
       "      <td>2.668047</td>\n",
       "      <td>0.134988</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.682469</td>\n",
       "      <td>2.661125</td>\n",
       "      <td>0.137421</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.675227</td>\n",
       "      <td>2.660346</td>\n",
       "      <td>0.137704</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.672274</td>\n",
       "      <td>2.661764</td>\n",
       "      <td>0.137996</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.677112</td>\n",
       "      <td>2.664571</td>\n",
       "      <td>0.137004</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.826339</td>\n",
       "      <td>2.699657</td>\n",
       "      <td>0.126101</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.715293</td>\n",
       "      <td>2.653438</td>\n",
       "      <td>0.139223</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.672793</td>\n",
       "      <td>2.644500</td>\n",
       "      <td>0.144034</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.653523</td>\n",
       "      <td>2.637554</td>\n",
       "      <td>0.145043</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.637591</td>\n",
       "      <td>2.633752</td>\n",
       "      <td>0.146116</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.628627</td>\n",
       "      <td>2.628540</td>\n",
       "      <td>0.147238</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.617568</td>\n",
       "      <td>2.627532</td>\n",
       "      <td>0.147655</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.610187</td>\n",
       "      <td>2.627121</td>\n",
       "      <td>0.147497</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 5e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.607193</td>\n",
       "      <td>2.626788</td>\n",
       "      <td>0.147338</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.608798</td>\n",
       "      <td>2.627914</td>\n",
       "      <td>0.147225</td>\n",
       "      <td>02:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.609551</td>\n",
       "      <td>2.626566</td>\n",
       "      <td>0.146921</td>\n",
       "      <td>02:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.604771</td>\n",
       "      <td>2.626820</td>\n",
       "      <td>0.147906</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.597393</td>\n",
       "      <td>2.627707</td>\n",
       "      <td>0.147547</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.588801</td>\n",
       "      <td>2.628191</td>\n",
       "      <td>0.147038</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.579679</td>\n",
       "      <td>2.629887</td>\n",
       "      <td>0.146867</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.571156</td>\n",
       "      <td>2.630000</td>\n",
       "      <td>0.147338</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.563926</td>\n",
       "      <td>2.631244</td>\n",
       "      <td>0.146416</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.561540</td>\n",
       "      <td>2.631273</td>\n",
       "      <td>0.146287</td>\n",
       "      <td>02:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(10, 1e-3, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the model and transfer over to classification.\n",
    "\n",
    "#### A note on fine tuning\n",
    "\n",
    "If we were to follow ULMFiT proper, the next step would be to fine tune the language model on the promoter corpus. In practice I have found that trying to fine tune the language model in this way quickly overfits, leading to worse classification performance. I believe this is due to the total text length of the promoter corpus. I will revisit this later with a larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('coli_only_LM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save_encoder('coli_only_LM_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Now we run the classification procedure exactly the same as the last notebook. The only difference is now we initialize the classification model with the encoder (embedding + LSTMs) of the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv(path/'e_coli_promoters_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>Locus</th>\n",
       "      <th>Location</th>\n",
       "      <th>Sample Location</th>\n",
       "      <th>Orientation</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>Promoter</th>\n",
       "      <th>Independent</th>\n",
       "      <th>set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['yaaX']</td>\n",
       "      <td>['b0005']</td>\n",
       "      <td>[5233:5530](+)</td>\n",
       "      <td>[5133:5283](+)</td>\n",
       "      <td>forward</td>\n",
       "      <td>GTAACTTAGAGATTAGGATTGCGGAGAATAACAACCGCCGTTCTCA...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['talB']</td>\n",
       "      <td>['b0008']</td>\n",
       "      <td>[8237:9191](+)</td>\n",
       "      <td>[8137:8287](+)</td>\n",
       "      <td>forward</td>\n",
       "      <td>ATAACCGTCTTGTCGGCGGTTGCGCTGACGTTGCGTCGTGATATCA...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['yaaW']</td>\n",
       "      <td>['b0011']</td>\n",
       "      <td>[10642:11356](-)</td>\n",
       "      <td>[11306:11456](-)</td>\n",
       "      <td>reverse</td>\n",
       "      <td>TCAAAAATCACCTTTTCGGGTCATACGGTGAACTCATCGGATATGG...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['hokC']</td>\n",
       "      <td>['b4412']</td>\n",
       "      <td>[16750:16903](-)</td>\n",
       "      <td>[16853:17003](-)</td>\n",
       "      <td>reverse</td>\n",
       "      <td>AAAGCCCCGAGTGATATTTTACCATCAACCCGAGGCCTCCTATATG...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['nhaA']</td>\n",
       "      <td>['b0019']</td>\n",
       "      <td>[17488:18655](+)</td>\n",
       "      <td>[17388:17538](+)</td>\n",
       "      <td>forward</td>\n",
       "      <td>TAAAAAACGAATTATTCCTACACTATAATCTGATTTTAACGATGAT...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gene      Locus          Location   Sample Location Orientation  \\\n",
       "0  ['yaaX']  ['b0005']    [5233:5530](+)    [5133:5283](+)     forward   \n",
       "1  ['talB']  ['b0008']    [8237:9191](+)    [8137:8287](+)     forward   \n",
       "2  ['yaaW']  ['b0011']  [10642:11356](-)  [11306:11456](-)     reverse   \n",
       "3  ['hokC']  ['b4412']  [16750:16903](-)  [16853:17003](-)     reverse   \n",
       "4  ['nhaA']  ['b0019']  [17488:18655](+)  [17388:17538](+)     forward   \n",
       "\n",
       "                                            Sequence  Promoter  Independent  \\\n",
       "0  GTAACTTAGAGATTAGGATTGCGGAGAATAACAACCGCCGTTCTCA...         1        False   \n",
       "1  ATAACCGTCTTGTCGGCGGTTGCGCTGACGTTGCGTCGTGATATCA...         1        False   \n",
       "2  TCAAAAATCACCTTTTCGGGTCATACGGTGAACTCATCGGATATGG...         1        False   \n",
       "3  AAAGCCCCGAGTGATATTTTACCATCAACCCGAGGCCTCCTATATG...         1        False   \n",
       "4  TAAAAAACGAATTATTCCTACACTATAATCTGATTTTAACGATGAT...         1        False   \n",
       "\n",
       "     set  \n",
       "0  train  \n",
       "1  train  \n",
       "2  train  \n",
       "3  train  \n",
       "4  train  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = classification_df[classification_df.set == 'train']\n",
    "valid_df = classification_df[classification_df.set == 'valid']\n",
    "test_df = classification_df[classification_df.set == 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Vocabulary\n",
    "\n",
    "Here we create a dataloader for tokenizing and numericalizing genomic sequences, same as before. However, we now pass in the vocabulary of the language model as a parameter for the classification dataloader. This ensures the mapping from k-mer to integer to embedding stays the same.\n",
    "\n",
    "## If you do not do this, everything will fail\n",
    "\n",
    "The exact order of the numericalization is based on the order in which tokens are processed. Different datasets or different shuffles of the same dataset __will__ have different vocabulary orders. If you try to transfer over a model with an incorrect vocabulary, it will basically refuse to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = np.load(path/'coli_vocab.npy')\n",
    "model_vocab = GenomicVocab(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = Tokenizer(GenomicTokenizer, n_cpus=1, pre_rules=[], post_rules=[], special_cases=['xxpad'])\n",
    "data_clas = GenomicTextClasDataBunch.from_df(path, train_df, valid_df, tokenizer=tok, vocab=model_vocab,\n",
    "                                             text_cols='Sequence', label_cols='Promoter', bs=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create the same classification model as before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clas_config = dict(emb_sz=400, n_hid=1150, n_layers=3, pad_token=0, qrnn=False, output_p=0.4, \n",
    "                       hidden_p=0.2, input_p=0.6, embed_p=0.1, weight_p=0.5)\n",
    "drop_mult = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = get_model_clas(data_clas, drop_mult, clas_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(1025, 400, padding_idx=0)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(1025, 400, padding_idx=0)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1150, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1150, 1150, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1150, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.24, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the encoder of the language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load_encoder('coli_only_LM_enc')\n",
    "learn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5' class='' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      71.43% [5/7 00:54<00:21]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.794743</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.790114</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.719954</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.628070</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.557531</td>\n",
       "      <td>#na#</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='12' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      75.00% [12/16 00:07<00:02 1.6362]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training procedure\n",
    "\n",
    "Here we follow the ULMFiT procedure of training with gradual unfreezing. We first train only the new classification layer of the model, then gradually the lower LSTM and embedding layers.\n",
    "\n",
    "You can see here that after a single epoch of training only the linear section (keeping the embedding/LSTMs as is from the language model) the classification model has achieved the same accuracy as the final model without pretraining.\n",
    "\n",
    "When the entire model is being trained, we use discriminitive learning rates to train the lower layers of the model at a lower learning rate than the higher layers. This allows us to apply larger parameter updates to the new linear classification head, and smaller updates to the well-trained embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.482926</td>\n",
       "      <td>0.556148</td>\n",
       "      <td>0.789333</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.434624</td>\n",
       "      <td>0.469060</td>\n",
       "      <td>0.854667</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.408330</td>\n",
       "      <td>0.379977</td>\n",
       "      <td>0.857333</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(3, 2e-2, moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.362193</td>\n",
       "      <td>0.310986</td>\n",
       "      <td>0.870667</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.317043</td>\n",
       "      <td>0.272745</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.272265</td>\n",
       "      <td>0.274141</td>\n",
       "      <td>0.894667</td>\n",
       "      <td>00:14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-2)\n",
    "learn.fit_one_cycle(3, slice(1e-2/(2.6**4),1e-2), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.199897</td>\n",
       "      <td>0.287533</td>\n",
       "      <td>0.884000</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.189302</td>\n",
       "      <td>0.287093</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.168930</td>\n",
       "      <td>0.277572</td>\n",
       "      <td>0.897333</td>\n",
       "      <td>00:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.freeze_to(-3)\n",
    "learn.fit_one_cycle(3, slice(5e-3/(2.6**4),5e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.134295</td>\n",
       "      <td>0.274154</td>\n",
       "      <td>0.902667</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.133595</td>\n",
       "      <td>0.282462</td>\n",
       "      <td>0.901333</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.123552</td>\n",
       "      <td>0.287639</td>\n",
       "      <td>0.904000</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.116407</td>\n",
       "      <td>0.297901</td>\n",
       "      <td>0.909333</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110118</td>\n",
       "      <td>0.295595</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit_one_cycle(5, slice(1e-3/(2.6**4),1e-3), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.097072</td>\n",
       "      <td>0.292118</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.098271</td>\n",
       "      <td>0.292845</td>\n",
       "      <td>0.910667</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.098067</td>\n",
       "      <td>0.292639</td>\n",
       "      <td>0.909333</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.098649</td>\n",
       "      <td>0.295974</td>\n",
       "      <td>0.910667</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.098564</td>\n",
       "      <td>0.294947</td>\n",
       "      <td>0.910667</td>\n",
       "      <td>00:31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5, slice(1e-4/(2.6**4),1e-4), moms=(0.8,0.7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/wd_4tb/shared_disk_wd4tb/mattscicluna/data/genomic_ulmfit/ecoli/models/coli_coli_pretrain.pth')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.save('coli_coli_pretrain', return_path=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clas = GenomicTextClasDataBunch.from_df(path, train_df, test_df, tokenizer=tok, vocab=model_vocab,\n",
    "                                            text_cols='Sequence', label_cols='Promoter', bs=300)\n",
    "learn.data = data_clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8987951807228916\n",
      "False Positives: 0.033734939759036145\n",
      "False Negatives: 0.06746987951807229\n",
      "Recall: 0.8650602409638555\n",
      "Precision: 0.9276485788113695\n",
      "Specificity: 0.9325301204819277\n",
      "MCC: 0.7994119723393397\n"
     ]
    }
   ],
   "source": [
    "get_scores(learn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the naive model, accuracy has increased from 83.4% to 91.9%, precision has increased from 0.84 to 0.94, recall has increased from 0.81 to 0.89, and the correlation coefficient has increased from 0.67 to 0.83.\n",
    "\n",
    "The model is also much more stable during training and gives more reproducible results. Unsupervised pretraining helps a lot.\n",
    "\n",
    "In fact, the best way to improve the model from this point is not to train more on the promoter dataset, but to create a better genomic language model from more genomic data. This is detailed in the next notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (genomic_ulmfit)",
   "language": "python",
   "name": "genomic_ulmfit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
